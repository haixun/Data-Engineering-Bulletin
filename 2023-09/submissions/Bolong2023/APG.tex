\subsection{Graph-based Methods}
% Graph-based methods have recently come to the forefront as a superior approach for Approximate Nearest Neighbor (ANN) search. They leverage the power of proximity graphs (PG) and have demonstrated superior performance in terms of both accuracy and efficiency \cite{DBLP:journals/pami/MalkovY20,DBLP:journals/pr/MunozGDT19,DBLP:journals/pvldb/WangXY021}.
% The fundamental structure of graph-based methods is a proximity graph, represented as $G=(V,E)$. Here, the vertex set $V$ symbolizes all data points in the dataset $\DD$, while the edge set $E$ encompasses all edges between vertices if the corresponding points are sufficiently proximate in the original space. 
% As it is computationally challenging to identify neighbors for each vertex, the construction cost of an exact proximity graph escalates to a minimum of $O(n^2)$ distance computations. This is prohibitively expensive for large-scale datasets. So, even though many well-designed graph structure has been used for NNS in multi-dimensional space several decades ago, such as MRNG \cite{DBLP:journals/dam/JaromczykK91}, Delaunay Graph and NN graph, they are hardly adaptive for high-dimensional ANNS due to the high indexing cost for a long time.

\textbf{Evolution.}
Existing graph-based methods concentrate on devising more efficient strategies to construct an approximate proximity graph (APG) while ensuring robust query performance. 
NN-Descent is a prevalent technique for constructing approximate Nearest Neighbor (NN) graphs. This method involves building an Approximate Proximity Graph (APG) from a random graph, with the edges for each point updated iteratively through a local search among the query's close neighbors. The construction complexity of NN-Descent is reduced to $\tilde{O}(n^{1.14})$, making it significantly more efficient than brute-force methods. The NN-Descent algorithm is employed in numerous graph-based approaches, such as EFANNA \cite{DBLP:journals/corr/FuC16}, NSG \cite{DBLP:journals/pvldb/FuXWC19} and others \cite{DBLP:journals/corr/abs-1804-03032,DBLP:journals/corr/abs-1908-00814}. Several derivatives of this algorithm have also been developed \cite{DBLP:conf/wims/BraticHKOR18}.
On the other hand, the Hierarchical Navigable Small World (HNSW) algorithm constructs its graph by sequentially inserting points. When inserting a point, denoted as $o$, the number of layers $o$ should be placed in is determined through a random number. A query is then conducted for $o$ in the current index, and $o$'s neighbors are chosen from the obtained results. Additionally, HNSW employs an edge occlusion rule to decrease the out-degree, a procedure proven to be identical to the one used in NSG. This rule enhances the distribution diversity of neighbors and boosts query efficiency. Known for its superior performance in addressing the ANN problem, HNSW is implemented in several widely-used libraries like NMSLib \cite{nmslib} and Faiss \cite{faiss}, which offer efficient tools for similarity search.

\textbf{Challenge: Index Update in APGs.}
%While APG emerges to be the most promising methods for solving ANN problem, it becomes a challenge to update APGs for dynamic datasets. 
%As the dataset evolves, many points in the proximity graph requires to be inserted and deleted. 
%Inserting a point in the APG is rather easy by using the similar strategy as consecutive insertion strategy. However, it is hard to delete points in the APG since the point is connected to other points and there are many edges required to be dropped. There are two typical policies to address the deletions in an APG. The first policy is to drop graph vertices corresponding to deleted points. The points, including its in-edges and out-edges are all deleted. The biggest problem of this policy is that it will make some vertex connected to it become sparse, \ie the number of edges of these points is small, which will degrade the graph quality.
%The second policy is that when deleting vertex $o$, for any pair of directed edges $(o_{in}\to o)$ and ($o\to o_{out}$) in the graph, we add the edge ($o_{in}\to o_{out}$) in the updated the edge set of $o_{in}$. 
%This policy address the problem in the former policy and ensures the graph quality not to degrade during updating but heavily increases the deletion cost because it is time-consuming to update the edge sets of all $o_{in}$s. So, it is challenging to ensure the graph quality and update efficiency when updating APGs.
While APG has emerged as the most promising method for solving ANN problems, updating APGs for dynamic datasets can be quite challenging. As the dataset evolves, many points in the proximity graph need to be inserted and deleted. Inserting a point in the APG is relatively easy using the same strategy as the consecutive insertion strategy. However, deleting points in the APG is difficult as the point is connected to other points and many edges need to be dropped. There are two typical policies to address deletions in an APG \cite{DBLP:journals/corr/abs-2105-09613}. The first policy is to drop graph vertices corresponding to deleted points, including their in-edges and out-edges. However, this policy can make some vertices connected to it become sparse, resulting in a degradation of graph quality. The second policy is that when deleting vertex $o$, for any pair of directed edges $(o_{in}\to o)$ and $(o\to o_{out})$ in the graph, we add the edge $(o_{in}\to o_{out})$ in the updated edge set of $o_{in}$. This policy addresses the problem in the former policy and ensures the graph quality does not degrade during updating, but heavily increases the deletion cost because it is time-consuming to update the edge sets of all $o_{in}$s. Therefore, ensuring graph quality and update efficiency when updating APGs is a challenging task.

\textbf{SOTA Graph based Index: LSH-APG \cite{DBLP:journals/pvldb/ZhaoTHZZ23}.} 
LSH-APG is an innovative graph-based method that leverages lightweight LSH indexes to construct the APG and expedite efficient Approximate Nearest Neighbor (ANN) query processing. 
LSH indexes, while swiftly constructed, often fall short in terms of query accuracy. On the other hand, graph-based methods excel in query processing performance but are hindered by the high construction cost due to their intricate construction and edge selection strategies. 
LSH-APG aims to mitigate these limitations inherent in both LSH and graph-based methods. It utilizes LSH indexes to quickly retrieve preliminary query results as the starting point for a search in an APG, then employs graph-based techniques to further refine the accuracy of the query result. 
In a departure from HNSW and NSG, which reduce the number of edges based on the edge occlusion rule, LSH-APG introduces an accurate and scalable pruning strategy to filter out neighbors distant from the query point. This approach markedly reduces the number of points accessed during graph search, effectively boosting query efficiency without increasing the construction cost. 
To construct the graph index, LSH-APG employs the consecutive insertion strategy where LSH framework can help find the candidate neighbors. All points are consecutively incorporated into the APG, where each point is treated as a query point and inserted into the graph index based on its nearest neighbors. It addresses the issue of high construction cost with the assistance of the LSH framework.
This strategy not only curtails construction cost by enhancing search efficiency via the LSH framework, but also allows for a formal correctness and complexity analysis of LSH-APG. The theoretical result show that LSH-APG have a nearly $O(n)$ query cost. 

%Moreover, LSH-APG designs a "mark-and-delete" policy to alleviate for index update, which pursues for a good balance between the graph quality and updating efficiency. To delete a point $o$ in the graph indexes, LSH-APG first marks the points $o$ and all of its out-edges. We usually only store the out-edges but not in-edges in APGs. Finding in-edges is also an uneasy task to be considered in the above two policies. 
%LSH-APG adopts a approximate query algorithm to find the in-edges. The query cost is bounded by a given threshold $C_{Dm}$ to control the deletion efficiency. Then, for an in-edge of $o$ not found in the range search, we leave it to the deletion procedure in the following queries. If it is found during an ANN query later, we discard it and decrease the in-degree of $o$ by one. Once the in-degree of $o$ becomes $0$, we discard all the out-edges of $o$ and $o$ itself. Finally, to avoid some in-edges not being found for a long time and thus wasting the space, we also traverse the graph and discard all the edges to be deleted when their amount reaches 10$\%$ of the total number of edges in LSH-APG. To ensure the graph quality, LSH-APG controls the out-degree of each vertex to be within an interval $[T,2T]$. So, when we mark an edge $(u,o)$ as deletion, we will check whether $u$'s out-degree decreases to be less than $T$. If so, we will increase the number of $u$'s neighbors to $T'$ by finding points in neighbors of $u$'s neighbors. By this manner, LSH-APG reduces the bad influence of the deletion on the graph quality with an acceptable cost.
Furthermore, LSH-APG has designed a "mark-and-delete" policy to alleviate index update issues, which aims to strike a balance between graph quality and updating efficiency. To delete a point $o$ in the graph indexes, LSH-APG first marks $o$ and all its out-edges. Typically, only out-edges are stored in APGs, and finding in-edges is a challenging task that is not considered in the previous two policies. To address this, LSH-APG uses an approximate query algorithm to find the in-edges, with the query cost bounded by a given threshold $C_{Dm}$ to control deletion efficiency. If an in-edge of $o$ is not found in the search, it is left for deletion in subsequent queries. If it is found during an ANN query later, it is discarded, and the in-degree of $o$ is decreased by one. Once the in-degree of $o$ becomes zero, all its out-edges and $o$ itself are discarded. To prevent in-edges from occupying space for an extended period, LSH-APG also traverses the graph and discards all edges to be deleted when their number reaches 10$\%$ of the total number of edges in LSH-APG. To ensure graph quality, LSH-APG controls the out-degree of each vertex to be within the interval $[T,2T]$. When an edge $(u,o)$ is marked for deletion, LSH-APG checks whether $u$'s out-degree decreases to less than $T$. If so, the number of $u$'s neighbors is increased to $2T$ by finding points in the neighbors of $u$'s neighbors. This approach reduces the negative impact of deletion on graph quality with an acceptable cost.

