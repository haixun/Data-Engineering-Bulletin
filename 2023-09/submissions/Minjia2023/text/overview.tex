\vspace{-1em}
\section{Preliminaries}
\label{minjia_sec:preliminaries}

\noindent
\textbf{Similarity graph.} A similarity graph is a directed graph $G=(V, E)$, where each vertex $v_i \in V$ corresponds to one of the vectors $v_i$ in a set of $N$ $d$-dimensional embedding vectors $v=\{v_1,...,v_N\}$. In practice, embedding vectors are generated by entities in a problem domain (e.g., a video or image in a recommendation system), which carry semantic meanings. The vertices $v_i$ and $v_j$ are connected by an edge if $v_j$ belongs to the set of $M$ relative nearest neighbors of $v_i$, determined by the similarity graph construction algorithm (e.g., NSG~\cite{fu2019fast}). There are no self-edge or duplicate edges in the graph. 

\noindent
\textbf{Top-K search.} The search in a similarity graph is performed via the \SeqFullName (\SeqShortName)~\cite{fu2019fast}, which aims to search only a small subset of the graph nodes to find the top-K nearest neighbors based on their closeness (e.g., Euclidean distance) to the query. BFiS starts at a chosen (e.g., medoid or random) point of the graph and greedily traverses the graph's edges by getting closer to the nearest neighbors at each step until it converges to a local optimum  (i.e., found top-K near neighbors). Algorithm~\ref{minjia_algo:seq_greedy_search} shows its basic idea. The search algorithm maintains a priority queue of size $L$ with graph nodes ($L \ge K$), indicating which neighbors should be visited by the search process. In the beginning, all nodes are initially in an unchecked state. During graph traversal, the algorithm first selects the closest unchecked node $v_i$ from the queue, called an active node (Line~\ref{minjia_algo_line:SGS_first_unchecked}), and performs a node expansion. A node expansion computes the pair-wise distance of all neighbors of $v_i$ to the query (Line~\ref{minjia_algo_line:SGS_expand_1}-\ref{minjia_algo_line:SGS_expand_2}). After the node expansion, the search inserts promising neighbors into the priority queue as new unchecked candidates for future expansion. The candidates in the priority queue are sorted according to their distance to the query, so less promising candidates will be popped out as new ones are added (Line~\ref{minjia_algo_line:queue_resize}). The search iteratively expands unchecked nodes based on their closeness (e.g., Euclidean distance) to the query. The search \textbf{\emph{converges}} when the priority queue has at least $K$ candidates and there are no unchecked nodes in it, indicating that it has reached a local optimum. 

\input{text/algo_seq_greedy_search}

\noindent
\textbf{Metric.} In practice, finding the exact top-$K$ can be very time-consuming. As a result, the search process only examines a subset of vectors in the similarity graph, leading to an \emph{accuracy-vs-latency} trade-off. The accuracy is often measured by the \emph{recall}, which is the fraction of true nearest neighbors ($R$) in retrieved top-K candidates ($R'$), defined as follows~\cite{fu2016efanna}:
\begin{align} \label{minjia_formula:recall}
    Recall(R') = \frac{\left | R' \cap R \right |}{\left | R' \right |} = \frac{\left | R' \cap R \right |}{K}
\end{align}
A high \emph{recall} is desired as low accurate results degrade user satisfaction.
On the other hand, the latency measures the time spent to find the top-$K$ nearest neighbors. Low latency is crucial, especially to enable ANN search for online interactive applications. 

Given the preliminaries, we now define the exact problem we are tackling in this paper:

\noindent
\textbf{Problem definition.} Considering a similarity graph and a multi-core architecture with $P$ processors, our goal is to design a parallel search algorithm such that the search latency to reach a given recall target is minimized. 






