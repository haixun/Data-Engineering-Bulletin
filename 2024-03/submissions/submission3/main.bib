@article{groth2013transparency,
  title={Transparency and reliability in the data supply chain},
  author={Groth, Paul},
  journal={IEEE Internet Computing},
  volume={17},
  number={2},
  pages={69--71},
  year={2013},
  publisher={IEEE}
}

@inproceedings{markov2023holistic,
  title={A holistic approach to undesired content detection in the real world},
  author={Markov, Todor and Zhang, Chong and Agarwal, Sandhini and Nekoul, Florentine Eloundou and Lee, Theodore and Adler, Steven and Jiang, Angela and Weng, Lilian},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={12},
  pages={15009--15018},
  year={2023}
}

@misc{huggingtransformers,
  author={{HuggingFace}},
  title={{transformers package}},
  year={2024},
  url={https://pypi.org/project/transformers/}
}

@misc{cdcpulsenet,
  author={{Centers for Disease Control \& Prevention}},
  title={{PulseNet}},
  year={2024},
  url={https://www.cdc.gov/pulsenet/index.html}
}

@misc{fdaout,
  author={{U.S. Food \& Drug Administration}},
  title={{Outbreaks of Foodborne Illness}},
  year={2024},
  url={https://www.fda.gov/food/recalls-outbreaks-emergencies/outbreaks-foodborne-illness}
}

@misc{fdanewport,
  author={{U.S. Food \& Drug Administration}},
  title={{Outbreak of Salmonella Newport Infections Linked to Onions}},
  year={2024},
  url={https://www.cdc.gov/salmonella/newport-07-20/index.html}
}


@misc{fdafaq,
  author={{U.S. Food \& Drug Administration}},
  title={{Frequently Asked Questions: FSMA Food Traceability Rule}},
  year={2024},
  url={https://www.fda.gov/food/food-safety-modernization-act-fsma/frequently-asked-questions-fsma-food-traceability-rule}
}

@misc{fdaftl,
  author={{U.S. Food \& Drug Administration}},
  title={{Food Traceability List}},
  year={2024},
  url={https://www.fda.gov/food/food-safety-modernization-act-fsma/food-traceability-list}
}

@misc{fdatp,
  author={{National Archives}},
  title={{Code of Federal Regulations - Traceability Plan}},
  year={2024},
  url={https://www.ecfr.gov/current/title-21/chapter-I/subchapter-A/part-1/subpart-S/subject-group-ECFRe6c9096adb572d4}
}



@inproceedings{li2023macaroni,
  title={Macaroni: Crawling and Enriching Metadata from Public Model Zoos},
  author={Li, Ziyu and Kant, Henk and Hai, Rihan and Katsifodimos, Asterios and Bozzon, Alessandro},
  booktitle={International Conference on Web Engineering},
  pages={376--380},
  year={2023},
  organization={Springer}
}

@article{li2023metadata,
  title={Metadata Representations for Queryable Repositories of Machine Learning Models},
  author={Li, Ziyu and Kant, Henk and Hai, Rihan and Katsifodimos, Asterios and Brambilla, Marco and Bozzon, Alessandro},
  journal={IEEE Access},
  year={2023},
  publisher={IEEE}
}

@inproceedings{sagadeeva2021sliceline,
  title={Sliceline: Fast, linear-algebra-based slice finding for ml model debugging},
  author={Sagadeeva, Svetlana and Boehm, Matthias},
  booktitle={Proceedings of the 2021 International Conference on Management of Data},
  pages={2290--2299},
  year={2021}
}

@inproceedings{asudeh2019assessing,
  title={Assessing and remedying coverage for a given dataset},
  author={Asudeh, Abolfazl and Jin, Zhongjun and Jagadish, HV},
  booktitle={2019 IEEE 35th International Conference on Data Engineering (ICDE)},
  pages={554--565},
  year={2019},
  organization={IEEE}
}

@article{lin2020identifying,
  title={Identifying insufficient data coverage in databases with multiple relations},
  author={Lin, Yin and Guan, Yifan and Asudeh, Abolfazl and Jagadish, HV},
  journal={Proceedings of the VLDB Endowment},
  volume={13},
  number={11},
  year={2020}
}


@article{li2021prefix,
  title={Prefix-Tuning: Optimizing Continuous Prompts for Generation},
  author={Li, Xiang Lisa and others},
  journal={ACL},
  year={2021}
}

@article{lester2021power,
  title={The power of scale for parameter-efficient prompt tuning},
  author={Lester, Brian and others},
  journal={EMNLP},
  year={2021}
}

@article{liu2023gpt,
  title={{GPT understands, too}},
  author={Liu, Xiao and others},
  journal={AI Open},
  year={2023}
}

@article{yeh2018representer,
  title={Representer point selection for explaining deep neural networks},
  author={Yeh, Chih-Kuan and Kim, Joon and Yen, Ian En-Hsu and Ravikumar, Pradeep K},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@InProceedings{pmlr-v70-koh17a,
  title =    {Understanding Black-box Predictions via Influence Functions},
  author =       {Pang Wei Koh and Percy Liang},
  booktitle =    {Proceedings of the 34th International Conference on Machine Learning},
  pages =    {1885--1894},
  year =   {2017},
  editor =   {Precup, Doina and Teh, Yee Whye},
  volume =   {70},
  series =   {Proceedings of Machine Learning Research},
  month =    {06--11 Aug},
  publisher =    {PMLR},
  pdf =    {http://proceedings.mlr.press/v70/koh17a/koh17a.pdf},
  url =    {https://proceedings.mlr.press/v70/koh17a.html},
  abstract =   {How can we explain the predictions of a black-box model? In this paper, we use influence functions — a classic technique from robust statistics — to trace a model’s prediction through the learning algorithm and back to its training data, thereby identifying training points most responsible for a given prediction. To scale up influence functions to modern machine learning settings, we develop a simple, efficient implementation that requires only oracle access to gradients and Hessian-vector products. We show that even on non-convex and non-differentiable models where the theory breaks down, approximations to influence functions can still provide valuable information. On linear models and convolutional neural networks, we demonstrate that influence functions are useful for multiple purposes: understanding model behavior, debugging models, detecting dataset errors, and even creating visually-indistinguishable training-set attacks.}
}


@inproceedings{schelter2019differential,
  title={Differential data quality verification on partitioned data},
  author={Schelter, Sebastian and Grafberger, Stefan and Schmidt, Philipp and Rukat, Tammo and Kiessling, Mario and Taptunov, Andrey and Biessmann, Felix and Lange, Dustin},
  booktitle={2019 IEEE 35th International Conference on Data Engineering (ICDE)},
  pages={1940--1945},
  year={2019},
  organization={IEEE}
}

@inproceedings{baylor2017tfx,
  title={Tfx: A tensorflow-based production-scale machine learning platform},
  author={Baylor, Denis and Breck, Eric and Cheng, Heng-Tze and Fiedel, Noah and Foo, Chuan Yu and Haque, Zakaria and Haykal, Salem and Ispir, Mustafa and Jain, Vihan and Koc, Levent and others},
  booktitle={Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages={1387--1395},
  year={2017}
}

@inproceedings{nigenda2022amazon,
  title={Amazon sagemaker model monitor: A system for real-time insights into deployed machine learning models},
  author={Nigenda, David and Karnin, Zohar and Zafar, Muhammad Bilal and Ramesha, Raghu and Tan, Alan and Donini, Michele and Kenthapadi, Krishnaram},
  booktitle={Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages={3671--3681},
  year={2022}
}

@inproceedings{dohmen2022gitschemas,
  title={Gitschemas: A dataset for automating relational data preparation tasks},
  author={D{\"o}hmen, Till and Hulsebos, Madelon and Beecks, Christian and Schelter, Sebastian},
  booktitle={2022 IEEE 38th International Conference on Data Engineering Workshops (ICDEW)},
  pages={74--78},
  year={2022},
  organization={IEEE}
}

@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={ICLR},
  year={2022}
}

@misc{shah2023ziplora,
      title={ZipLoRA: Any Subject in Any Style by Effectively Merging LoRAs}, 
      author={Viraj Shah and Nataniel Ruiz and Forrester Cole and Erika Lu and Svetlana Lazebnik and Yuanzhen Li and Varun Jampani},
      year={2023},
      eprint={2311.13600},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{mitchell2019model,
  title={Model cards for model reporting},
  author={Mitchell, Margaret and Wu, Simone and Zaldivar, Andrew and Barnes, Parker and Vasserman, Lucy and Hutchinson, Ben and Spitzer, Elena and Raji, Inioluwa Deborah and Gebru, Timnit},
  booktitle={Proceedings of the conference on fairness, accountability, and transparency},
  pages={220--229},
  year={2019}
}

@article{gebru2021datasheets,
  title={Datasheets for datasets},
  author={Gebru, Timnit and Morgenstern, Jamie and Vecchione, Briana and Vaughan, Jennifer Wortman and Wallach, Hanna and Iii, Hal Daum{\'e} and Crawford, Kate},
  journal={Communications of the ACM},
  volume={64},
  number={12},
  pages={86--92},
  year={2021},
  publisher={ACM New York, NY, USA}
}


@inproceedings{tae2019data,
  title={Data cleaning for accurate, fair, and robust models: A big data-AI integration approach},
  author={Tae, Ki Hyun and Roh, Yuji and Oh, Young Hun and Kim, Hyunsu and Whang, Steven Euijong},
  booktitle={Proceedings of the 3rd International Workshop on Data Management for End-to-End Machine Learning},
  pages={1--4},
  year={2019}
}

@article{whang2021responsible,
  title={Responsible AI Challenges in End-to-end Machine Learning},
  author={Whang, Steven Euijong and Tae, Ki Hyun and Roh, Yuji and Heo, Geon},
  journal={arXiv preprint arXiv:2101.05967},
  year={2021}
}


@article{zaharia2018accelerating,
  title={Accelerating the machine learning lifecycle with MLflow.},
  author={Zaharia, Matei and Chen, Andrew and Davidson, Aaron and Ghodsi, Ali and Hong, Sue Ann and Konwinski, Andy and Murching, Siddharth and Nykodym, Tomas and Ogilvie, Paul and Parkhe, Mani and others},
  journal={IEEE Data Eng. Bull.},
  volume={41},
  number={4},
  pages={39--45},
  year={2018}
}


@inproceedings{green2007provenance,
  title={Provenance semirings},
  author={Green, Todd J and Karvounarakis, Grigoris and Tannen, Val},
  booktitle={Proceedings of the twenty-sixth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems},
  pages={31--40},
  year={2007}
}

@inproceedings{amsterdamer2011provenance,
  title={Provenance for aggregate queries},
  author={Amsterdamer, Yael and Deutch, Daniel and Tannen, Val},
  booktitle={Proceedings of the thirtieth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems},
  pages={153--164},
  year={2011}
}

@article{tan2007provenance,
  title={Provenance in databases: Past, current, and future.},
  author={Tan, Wang Chiew and others},
  journal={IEEE Data Eng. Bull.},
  volume={30},
  number={4},
  pages={3--12},
  year={2007},
  publisher={Citeseer}
}

@Inproceedings{Schelter2017,
 author = {Sebastian Schelter and Joos-Hendrik Böse and Johannes Kirschnick and Thoralf Klein and Stephan Seufert},
 title = {Automatically tracking metadata and provenance of machine learning experiments},
 year = {2017},
 url = {https://www.amazon.science/publications/automatically-tracking-metadata-and-provenance-of-machine-learning-experiments},
 booktitle = {NeurIPS 2017},
}

@article{sheng2019woman,
  title={The woman worked as a babysitter: On biases in language generation},
  author={Sheng, Emily and Chang, Kai-Wei and Natarajan, Premkumar and Peng, Nanyun},
  journal={arXiv preprint arXiv:1909.01326},
  year={2019}
}

@article{hutchinson2020social,
  title={Social biases in NLP models as barriers for persons with disabilities},
  author={Hutchinson, Ben and Prabhakaran, Vinodkumar and Denton, Emily and Webster, Kellie and Zhong, Yu and Denuyl, Stephen},
  journal={arXiv preprint arXiv:2005.00813},
  year={2020}
}


@inproceedings{abid2021persistent,
  title={Persistent anti-muslim bias in large language models},
  author={Abid, Abubakar and Farooqi, Maheen and Zou, James},
  booktitle={Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society},
  pages={298--306},
  year={2021}
}


@inproceedings{lucy2021gender,
  title={Gender and representation bias in GPT-3 generated stories},
  author={Lucy, Li and Bamman, David},
  booktitle={Proceedings of the Third Workshop on Narrative Understanding},
  pages={48--55},
  year={2021}
}


@misc{facebookdata,
  author={{The Intercept}},
  title={{Facebook Engineers: We Have No Idea Where We Keep All Your Personal Data}},
  year={2022},
  url={https://theintercept.com/2022/09/07/facebook-personal-data-no-accountability/}
}

@article{torralba200880,
  title={80 million tiny images: A large data set for nonparametric object and scene recognition},
  author={Torralba, Antonio and Fergus, Rob and Freeman, William T},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={30},
  number={11},
  pages={1958--1970},
  year={2008},
  publisher={IEEE}
}

@article{birhane2023hate,
  title={On Hate Scaling Laws For Data-Swamps},
  author={Birhane, Abeba and Prabhu, Vinay and Han, Sang and Boddeti, Vishnu Naresh},
  journal={arXiv preprint arXiv:2306.13141},
  year={2023}
}

@article{schuhmann2022laion,
  title={Laion-5b: An open large-scale dataset for training next generation image-text models},
  author={Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={25278--25294},
  year={2022}
}

@misc{euaiact,
  author = {European Commission},
  title = {AI Act},
  url = {https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai}
}

@misc{digichina,
  author = {DigiChina -- Stanford University},
  title = {Internet Information Service Algorithmic Recommendation Management Provisions},
  url = {https://digichina.stanford.edu/work/translation-internet-information-service-algorithmic-recommendation-management-provisions-opinon-seeking-draft/}
}

@misc{cppa,
  author = {California Privacy Protection Agency},
  title = {California Consumer Privacy Act - Frequently Asked Questions},
  url = {https://cppa.ca.gov/faq.html#faq_res_1}
}  


@misc{GDPRart17,
  author = {{GDPR.eu}},
  howpublished = {https://gdpr.eu/article-17-right-to-be-forgotten},
  title = {{Article 17: Right to be forgotten}}
}

@misc{GDPRrec74,
  author = {{GDPR.eu}},
  howpublished = {https://gdpr.eu/recital-74-responsibility-and-liability-of-the-controller/},
  title = {{Recital 74: Responsibility and liability of the controller}}
}

@article{friedman1996bias,
  title={Bias in computer systems},
  author={Friedman, Batya and Nissenbaum, Helen},
  journal={ACM Transactions on information systems (TOIS)},
  volume={14},
  number={3},
  pages={330--347},
  year={1996},
  publisher={ACM New York, NY, USA}
}


@inproceedings{birhane2021large,
  title={Large image datasets: A pyrrhic win for computer vision?},
  author={Birhane, Abeba and Prabhu, Vinay Uday},
  booktitle={2021 IEEE Winter Conference on Applications of Computer Vision (WACV)},
  pages={1536--1546},
  year={2021},
  organization={IEEE}
}

@article{birhane2024ai,
  title={AI auditing: The Broken Bus on the Road to AI Accountability},
  author={Birhane, Abeba and Steed, Ryan and Ojewale, Victor and Vecchione, Briana and Raji, Inioluwa Deborah},
  journal={arXiv preprint arXiv:2401.14462},
  year={2024}
}

@inproceedings{mcgregor2021preventing,
  title={Preventing repeated real world AI failures by cataloging incidents: The AI incident database},
  author={McGregor, Sean},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={17},
  pages={15458--15463},
  year={2021}
}


@inproceedings{holstein2019improving,
  title={Improving fairness in machine learning systems: What do industry practitioners need?},
  author={Holstein, Kenneth and Wortman Vaughan, Jennifer and Daum{\'e} III, Hal and Dudik, Miro and Wallach, Hanna},
  booktitle={Proceedings of the 2019 CHI conference on human factors in computing systems},
  pages={1--16},
  year={2019}
}


@inproceedings{kamath2014realgraph,
  title={Realgraph: User interaction prediction at twitter},
  author={Kamath, Krishna and Sharma, Aneesh and Wang, Dong and Yin, Zhijun},
  booktitle={user engagement optimization workshop@ KDD},
  number={ii},
  year={2014}
}


@inproceedings{li2021cleanml,
  title={CleanML: A study for evaluating the impact of data cleaning on ml classification tasks},
  author={Li, Peng and Rao, Xi and Blase, Jennifer and Zhang, Yue and Chu, Xu and Zhang, Ce},
  booktitle={2021 IEEE 37th International Conference on Data Engineering (ICDE)},
  pages={13--24},
  year={2021},
  organization={IEEE}
}

@article{groth2013transparency,
  title={Transparency and reliability in the data supply chain},
  author={Groth, Paul},
  journal={IEEE Internet Computing},
  volume={17},
  number={2},
  pages={69--71},
  year={2013},
  publisher={IEEE}
}

@article{shahbazi2023through,
  title={Through the Fairness Lens: Experimental Analysis and Evaluation of Entity Matching},
  author={Shahbazi, Nima and Danevski, Nikola and Nargesian, Fatemeh and Asudeh, Abolfazl and Srivastava, Divesh},
  journal={VLDB},
  year={2023}
}

@inproceedings{guha2024automated,
  title={Automated Data Cleaning Can Hurt Fairness in Machine Learning-based Decision Making},
  author={Guha, Shubha and Khan, Falaah Arif and Stoyanovich, Julia and Schelter, Sebastian},
  booktitle={Transactions on Knowledge and Data Engineering (TKDE)},
  year={2024},
  organization={IEEE}
}



@article{narayanan21fairness,
  title={Fairness definitions and their politics},
  author={Narayanan, Arvind},
  journal={ACM FaccT},
  year={2018}
}

@inproceedings{schelter2020learning,
  title={Learning to validate the predictions of black box classifiers on unseen data},
  author={Schelter, Sebastian and Rukat, Tammo and Bie{\ss}mann, Felix},
  booktitle={Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data},
  pages={1289--1299},
  year={2020}
}

@inproceedings{lipton2018detecting,
  title={Detecting and correcting for label shift with black box predictors},
  author={Lipton, Zachary and Wang, Yu-Xiang and Smola, Alexander},
  booktitle={International conference on machine learning},
  pages={3122--3130},
  year={2018},
  organization={PMLR}
}

@inproceedings{hynes2017data,
  title={The data linter: Lightweight, automated sanity checking for ml data sets},
  author={Hynes, Nick and Sculley, D and Terry, Michael},
  booktitle={NIPS MLSys Workshop},
  volume={1},
  number={5},
  year={2017}
}


@article{hammoudeh2022training,
  title={Training data influence analysis and estimation: A survey},
  author={Hammoudeh, Zayd and Lowd, Daniel},
  journal={arXiv preprint arXiv:2212.04612},
  year={2022}
}

@inproceedings{redyuk2021automating,
  title={Automating Data Quality Validation for Dynamic Data Ingestion.},
  author={Redyuk, Sergey and Kaoudi, Zoi and Markl, Volker and Schelter, Sebastian},
  booktitle={EDBT},
  pages={61--72},
  year={2021}
}

@inproceedings{shankar2023automatic,
  title={Automatic and Precise Data Validation for Machine Learning},
  author={Shankar, Shreya and Fawaz, Labib and Gyllstrom, Karl and Parameswaran, Aditya},
  booktitle={Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
  pages={2198--2207},
  year={2023}
}

@misc{shankar2022observability,
      title={Towards Observability for Production Machine Learning Pipelines}, 
      author={Shreya Shankar and Aditya Parameswaran},
      year={2022},
      eprint={2108.13557},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@article{shankar2024spade,
  title={SPADE: Synthesizing Assertions for Large Language Model Pipelines},
  author={Shankar, Shreya and Li, Haotian and Asawa, Parth and Hulsebos, Madelon and Lin, Yiming and Zamfirescu-Pereira, JD and Chase, Harrison and Fu-Hinthorn, Will and Parameswaran, Aditya G and Wu, Eugene},
  journal={arXiv preprint arXiv:2401.03038},
  year={2024}
}

@article{olston2017tensorflow,
  title={Tensorflow-serving: Flexible, high-performance ml serving},
  author={Olston, Christopher and Fiedel, Noah and Gorovoy, Kiril and Harmsen, Jeremiah and Lao, Li and Li, Fangwei and Rajashekhar, Vinu and Ramesh, Sukriti and Soyke, Jordan},
  journal={arXiv preprint arXiv:1712.06139},
  year={2017}
}

@article{rabanser2019failing,
  title={Failing loudly: An empirical study of methods for detecting dataset shift},
  author={Rabanser, Stephan and G{\"u}nnemann, Stephan and Lipton, Zachary},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}


@inproceedings{chung2019slice,
  title={Slice finder: Automated data slicing for model validation},
  author={Chung, Yeounoh and Kraska, Tim and Polyzotis, Neoklis and Tae, Ki Hyun and Whang, Steven Euijong},
  booktitle={2019 IEEE 35th International Conference on Data Engineering (ICDE)},
  pages={1550--1553},
  year={2019},
  organization={IEEE}
}


@online{aiface2023,
  author = {Democracy~Now},
  title = {{Meet Porcha Woodruff, Detroit Woman Jailed While 8 Months Pregnant After False AI Facial Recognition}},
  year = 2023,
  howpublished = {\url{https://www.democracynow.org/2023/8/9/porcha_woodruff_false_facial_recognition_arrest}}
}

@online{aicheating2023,
  author = {The Markup},
  title = {{AI Detection Tools Falsely Accuse International Students of Cheating}},
  year = 2023,
  howpublished = {\url{https://themarkup.org/machine-learning/2023/08/14/ai-detection-tools-falsely-accuse-international-students-of-cheating}}
}

@online{aihealth2023,
  author = {Ars Technica},
  title = {{UnitedHealth uses AI model with 90\% error rate to deny care, lawsuit alleges}},
  year = 2023,
  howpublished = {\url{https://arstechnica.com/health/2023/11/ai-with-90-error-rate-forces-elderly-out-of-rehab-nursing-homes-suit-claims/}}
}


@online{airecipe2023,
  author = {The Guardian},
  title = {{ This article is more than 4 months old
Supermarket AI meal planner app suggests recipe that would create chlorine gas}},
  year = 2023,
  howpublished = {\url{https://www.theguardian.com/world/2023/aug/10/pak-n-save-savey-meal-bot-ai-app-malfunction-recipes}}
}

@article{chen2018my,
  title={Why is my classifier discriminatory?},
  author={Chen, Irene and Johansson, Fredrik D and Sontag, David},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{stoyanovich2022responsible,
  title={Responsible data management},
  author={Stoyanovich, Julia and Abiteboul, Serge and Howe, Bill and Jagadish, HV and Schelter, Sebastian},
  journal={Communications of the ACM},
  volume={65},
  number={6},
  pages={64--74},
  year={2022},
  publisher={ACM New York, NY, USA}
}

@article{birhane2021multimodal,
  title={Multimodal datasets: misogyny, pornography, and malignant stereotypes},
  author={Birhane, Abeba and Prabhu, Vinay Uday and Kahembwe, Emmanuel},
  journal={arXiv preprint arXiv:2110.01963},
  year={2021}
}

@inproceedings{guha2023automated,
  title={Automated data cleaning can hurt fairness in machine learning-based decision making},
  author={Guha, Shubha and Khan, Falaah Arif and Stoyanovich, Julia and Schelter, Sebastian},
  booktitle={2023 IEEE 39th International Conference on Data Engineering (ICDE)},
  pages={3747--3754},
  year={2023},
  organization={IEEE}
}

@online{aicsam2023,
  author = {404 Media},
  title = {{Largest Dataset Powering AI Images Removed After Discovery of Child Sexual Abuse Material}},
  year = 2023,
  howpublished = {\url{https://www.404media.co/laion-datasets-removed-stanford-csam-child-abuse/}}
}

@online{fda,
  author = {{U.S. Food and Drug Administration}},
  title = {{How the Food Traceability Rule works: Produce Supply Chain Example}},
  year = 2022,
  howpublished = {\url{https://www.youtube.com/watch?v=ZcSBvLQ6p6M}}
}

@article{schelter2018automating,
  title={Automating large-scale data quality verification},
  author={Schelter, Sebastian and Lange, Dustin and Schmidt, Philipp and Celikel, Meltem and Biessmann, Felix and Grafberger, Andreas},
  journal={Proceedings of the VLDB Endowment},
  volume={11},
  number={12},
  pages={1781--1794},
  year={2018},
  publisher={VLDB Endowment}
}

@inproceedings{breck2019data,
  title={Data Validation for Machine Learning.},
  author={Breck, Eric and Polyzotis, Neoklis and Roy, Sudip and Whang, Steven and Zinkevich, Martin},
  booktitle={MLSys},
  year={2019}
}

@article{grafberger2022data,
  title={Data distribution debugging in machine learning pipelines},
  author={Grafberger, Stefan and Groth, Paul and Stoyanovich, Julia and Schelter, Sebastian},
  journal={The VLDB Journal},
  volume={31},
  number={5},
  pages={1103--1126},
  year={2022},
  publisher={Springer}
}

@inproceedings{namaki2020vamsa,
  title={Vamsa: Automated provenance tracking in data science scripts},
  author={Namaki, Mohammad Hossein and Floratou, Avrilia and Psallidas, Fotis and Krishnan, Subru and Agrawal, Ashvin and Wu, Yinghui and Zhu, Yiwen and Weimer, Markus},
  booktitle={Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery \& data mining},
  pages={1542--1551},
  year={2020}
}

@inproceedings{jia2019towards,
  title={Towards efficient data valuation based on the shapley value},
  author={Jia, Ruoxi and Dao, David and Wang, Boxin and Hubis, Frances Ann and Hynes, Nick and G{\"u}rel, Nezihe Merve and Li, Bo and Zhang, Ce and Song, Dawn and Spanos, Costas J},
  booktitle={The 22nd International Conference on Artificial Intelligence and Statistics},
  pages={1167--1176},
  year={2019},
  organization={PMLR}
}

@inproceedings{ghorbani2019data,
  title={Data shapley: Equitable valuation of data for machine learning},
  author={Ghorbani, Amirata and Zou, James},
  booktitle={International conference on machine learning},
  pages={2242--2251},
  year={2019},
  organization={PMLR}
}

@inproceedings{wu2020complaint,
  title={Complaint-driven training data debugging for query 2.0},
  author={Wu, Weiyuan and Flokas, Lampros and Wu, Eugene and Wang, Jiannan},
  booktitle={Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data},
  pages={1317--1334},
  year={2020}
}

@inproceedings{pradhan2022interpretable,
  title={Interpretable data-based explanations for fairness debugging},
  author={Pradhan, Romila and Zhu, Jiongli and Glavic, Boris and Salimi, Babak},
  booktitle={Proceedings of the 2022 International Conference on Management of Data},
  pages={247--261},
  year={2022}
}

@inproceedings{schelter2023proactively,
  title={Proactively Screening Machine Learning Pipelines with ArgusEyes},
  author={Schelter, Sebastian and Grafberger, Stefan and Guha, Shubha and Karlas, Bojan and Zhang, Ce},
  booktitle={Companion of the 2023 International Conference on Management of Data},
  pages={91--94},
  year={2023}
}

@article{karlavs2022data,
  title={Data debugging with shapley importance over end-to-end machine learning pipelines},
  author={Karla{\v{s}}, Bojan and Dao, David and Interlandi, Matteo and Li, Bo and Schelter, Sebastian and Wu, Wentao and Zhang, Ce},
  journal={arXiv preprint arXiv:2204.11131},
  year={2022}
}

@inproceedings{yang2018nutritional,
author = {Yang, Ke and Stoyanovich, Julia and Asudeh, Abolfazl and Howe, Bill and Jagadish, HV and Miklau, Gerome},
title = {A Nutritional Label for Rankings},
year = {2018},
isbn = {9781450347037},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183713.3193568},
doi = {10.1145/3183713.3193568},
abstract = {Algorithmic decisions often result in scoring and ranking individuals to determine credit worthiness, qualifications for college admissions and employment, and compatibility as dating partners. While automatic and seemingly objective, ranking algorithms can discriminate against individuals and protected groups, and exhibit low diversity. Furthermore, ranked results are often unstable -- small changes in the input data or in the ranking methodology may lead to drastic changes in the output, making the result uninformative and easy to manipulate. Similar concerns apply in cases where items other than individuals are ranked, including colleges, academic departments, or products. Despite the ubiquity of rankers, there is, to the best of our knowledge, no technical work that focuses on making rankers transparent.In this demonstration we present Ranking Facts, a Web-based application that generates a "nutritional label" for rankings. Ranking Facts is made up of a collection of visual widgets that implement our latest research results on fairness, stability, and transparency for rankings, and that communicate details of the ranking methodology, or of the output, to the end user. We will showcase Ranking Facts on real datasets from different domains, including college rankings, criminal risk assessment, and financial services.},
booktitle = {Proceedings of the 2018 International Conference on Management of Data},
pages = {1773–1776},
numpages = {4},
keywords = {accountability, responsibly, data ethics, ranking, data, fairness, diversity, transparency, stability},
location = {Houston, TX, USA},
series = {SIGMOD '18}
}

@article{sandvig2014auditing,
  title={Auditing algorithms: Research methods for detecting discrimination on internet platforms},
  author={Sandvig, Christian and Hamilton, Kevin and Karahalios, Karrie and Langbort, Cedric},
  journal={Data and discrimination: converting critical concerns into productive inquiry},
  volume={22},
  number={2014},
  pages={4349--4357},
  year={2014}
}

@article{nguyen2022improving,
  title={Improving the generalizability of depression detection by leveraging clinical questionnaires},
  author={Nguyen, Thong and Yates, Andrew and Zirikly, Ayah and Desmet, Bart and Cohan, Arman},
  journal={arXiv preprint arXiv:2204.10432},
  year={2022}
}

@inproceedings{xu2021bot,
  title={Bot-adversarial dialogue for safe conversational agents},
  author={Xu, Jing and Ju, Da and Li, Margaret and Boureau, Y-Lan and Weston, Jason and Dinan, Emily},
  booktitle={Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={2950--2968},
  year={2021}
}

@inproceedings{dinan2022safetykit,
  title={SafetyKit: First aid for measuring safety in open-domain conversational systems},
  author={Dinan, Emily and Abercrombie, Gavin and Bergman, Stevie A and Spruit, Shannon and Hovy, Dirk and Boureau, Y-Lan and Rieser, Verena and others},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  year={2022},
  organization={Association for Computational Linguistics}
}

@misc{tensorflowPatterns21,
  author = {Rokni, Reza},
  title = {Using TFX inference with Dataflow for large scale ML inference patterns },
  year = 2021,
  journal={TensorFlow Blog},
  howpublished = {\url{https://blog.tensorflow.org/2021/05/using-tfx-inference-with-dataflow-for-large-scale-ml-inference-patterns.html}}
}

@misc{traceabilityAndReproducibility23,
  author = {Vechtomova, Maria},
  title = {Traceability \& Reproducibility},
  journal={Marvelous MLOps Substack},
  year={2023},
  howpublished = {\url{https://marvelousmlops.substack.com/p/traceability-and-reproducibility}}
}

@misc{howToMonitor23,
  author = {Oladele, Stephen},
  title = {A Comprehensive Guide on How to Monitor Your Models in Production},
  journal={NeptuneAI MLOps Blog},
  year ={2023},
  howpublished = {\url{https://neptune.ai/blog/how-to-monitor-your-models-in-production-guide}}
}

@inproceedings{chend23dynamicCorpora,
author = {Chen, Jiangui and Zhang, Ruqing and Guo, Jiafeng and de Rijke, Maarten and Chen, Wei and Fan, Yixing and Cheng, Xueqi},
title = {Continual Learning for Generative Retrieval over Dynamic Corpora},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3614821},
doi = {10.1145/3583780.3614821},
abstract = {Generative retrieval (GR) directly predicts the identifiers of relevant documents (i.e., docids) based on a parametric model. It has achieved solid performance on many ad-hoc retrieval tasks. So far, these tasks have assumed a static document collection. In many practical scenarios, however, document collections are dynamic, where new documents are continuously added to the corpus. The ability to incrementally index new documents while preserving the ability to answer queries with both previously and newly indexed relevant documents is vital to applying GR models. In this paper, we address this practical continual learning problem for GR. We put forward a novel Continual-LEarner for generatiVE Retrieval (CLEVER) model and make two major contributions to continual learning for GR: (i) To encode new documents into docids with low computational cost, we present Incremental Product Quantization, which updates a partial quantization codebook according to two adaptive thresholds; and (ii) To memorize new documents for querying without forgetting previous knowledge, we propose a memory-augmented learning mechanism, to form meaningful connections between old and new documents. Empirical results demonstrate the effectiveness and efficiency of the proposed model.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {306–315},
numpages = {10},
keywords = {document increment, generative retrieval, product quantization},
location = {<conf-loc>, <city>Birmingham</city>, <country>United Kingdom</country>, </conf-loc>},
series = {CIKM '23}
}

@inproceedings{Guo16traditionalIR,
author = {Guo, Jiafeng and Fan, Yixing and Ai, Qingyao and Croft, W. Bruce},
title = {A Deep Relevance Matching Model for Ad-hoc Retrieval},
year = {2016},
isbn = {9781450340731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2983323.2983769},
doi = {10.1145/2983323.2983769},
abstract = {In recent years, deep neural networks have led to exciting breakthroughs in speech recognition, computer vision, and natural language processing (NLP) tasks. However, there have been few positive results of deep models on ad-hoc retrieval tasks. This is partially due to the fact that many important characteristics of the ad-hoc retrieval task have not been well addressed in deep models yet. Typically, the ad-hoc retrieval task is formalized as a matching problem between two pieces of text in existing work using deep models, and treated equivalent to many NLP tasks such as paraphrase identification, question answering and automatic conversation. However, we argue that the ad-hoc retrieval task is mainly about relevance matching while most NLP matching tasks concern semantic matching, and there are some fundamental differences between these two matching tasks. Successful relevance matching requires proper handling of the exact matching signals, query term importance, and diverse matching requirements. In this paper, we propose a novel deep relevance matching model (DRMM) for ad-hoc retrieval. Specifically, our model employs a joint deep architecture at the query term level for relevance matching. By using matching histogram mapping, a feed forward matching network, and a term gating network, we can effectively deal with the three relevance matching factors mentioned above. Experimental results on two representative benchmark collections show that our model can significantly outperform some well-known retrieval models as well as state-of-the-art deep matching models.},
booktitle = {Proceedings of the 25th ACM International on Conference on Information and Knowledge Management},
pages = {55–64},
numpages = {10},
keywords = {semantic matching, relevance matching, ranking models, neural models, ad-hoc retrieval},
location = {Indianapolis, Indiana, USA},
series = {CIKM '16}
}

@inproceedings {baylor19tfxContinous,
author = {Denis Baylor and Kevin Haas and Konstantinos Katsiapis and Sammy Leong and Rose Liu and Clemens Menwald and Hui Miao and Neoklis Polyzotis and Mitchell Trott and Martin Zinkevich},
title = {Continuous Training for Production {ML} in the {TensorFlow} Extended ({{{{{TFX}}}}}) Platform},
booktitle = {2019 USENIX Conference on Operational Machine Learning (OpML 19)},
year = {2019},
isbn = {978-1-939133-00-7},
address = {Santa Clara, CA},
pages = {51--53},
url = {https://www.usenix.org/conference/opml19/presentation/baylor},
publisher = {USENIX Association},
month = may
}

@article{schelter2022screening,
  title={Screening Native ML Pipelines with “ArgusEyes”},
  author={Schelter, Sebastian and Grafberger, Stefan and Guha, Shubha and Sprangers, Olivier and Karla{\v{s}}, Bojan and Zhang, Ce},
  journal={CIDR},
  year={2022}
}

@article{grafberger2023mlwhatif,
author = {Grafberger, Stefan and Groth, Paul and Schelter, Sebastian},
title = {Automating and Optimizing Data-Centric What-If Analyses on~Native~ Machine~Learning~Pipelines},
year = {2023},
journal = {SIGMOD}
}

@article{grafberger2021demo,
author = {Grafberger, Stefan and Guha, Shubha and Stoyanovich, Julia and Schelter, Sebastian},
title = {MLINSPECT: A Data Distribution Debugger for Machine Learning Pipelines},
year = {2021},
journal = {SIGMOD}
}

@article{grafberger2023demo,
author = {Grafberger, Stefan and Guha, Shubha and Groth, Paul and Schelter, Sebastian},
title = {mlwhatif: What If You Could Stop Re-Implementing Your Machine Learning Pipeline Analyses over and over?},
year = {2023},
issue_date = {August 2023},
publisher = {VLDB Endowment},
volume = {16},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3611540.3611606},
doi = {10.14778/3611540.3611606},
abstract = {Software systems that learn from data with machine learning (ML) are used in critical decision-making processes. Unfortunately, real-world experience shows that the pipelines for data preparation, feature encoding and model training in ML systems are often brittle with respect to their input data. As a consequence, data scientists have to run different kinds of data centric what-if analyses to evaluate the robustness and reliability of such pipelines, e.g., with respect to data errors or preprocessing techniques. These what-if analyses follow a common pattern: they take an existing ML pipeline, create a pipeline variant by introducing a small change, and execute this variant to see how the change impacts the pipeline's output score.We recently proposed mlwhatif, a library that enables data scientists to declaratively specify what-if analyses for an ML pipeline, and to automatically generate, optimize and execute the required pipeline variants. We demonstrate how data scientists can leverage mlwhatif for a variety of pipelines and three different what-if analyses focusing on the robustness of a pipeline against data errors, the impact of data cleaning operations, and the impact of data preprocessing operations on fairness. In particular, we demonstrate step-by-step how mlwhatif generates and optimizes the required execution plans for the pipeline analyses. Our library is publicly available at https://github.com/stefan-grafberger/mlwhatif.},
journal = {Proc. VLDB Endow.},
month = {aug},
pages = {4002–4005},
numpages = {4}
}

@misc{mazumder2023dataperf,
      title={DataPerf: Benchmarks for Data-Centric AI Development}, 
      author={Mark Mazumder and Colby Banbury and Xiaozhe Yao and Bojan Karlaš and William Gaviria Rojas and Sudnya Diamos and Greg Diamos and Lynn He and Alicia Parrish and Hannah Rose Kirk and Jessica Quaye and Charvi Rastogi and Douwe Kiela and David Jurado and David Kanter and Rafael Mosquera and Juan Ciro and Lora Aroyo and Bilge Acun and Lingjiao Chen and Mehul Smriti Raje and Max Bartolo and Sabri Eyuboglu and Amirata Ghorbani and Emmett Goodman and Oana Inel and Tariq Kane and Christine R. Kirkpatrick and Tzu-Sheng Kuo and Jonas Mueller and Tristan Thrush and Joaquin Vanschoren and Margaret Warren and Adina Williams and Serena Yeung and Newsha Ardalani and Praveen Paritosh and Lilith Bat-Leah and Ce Zhang and James Zou and Carole-Jean Wu and Cody Coleman and Andrew Ng and Peter Mattson and Vijay Janapa Reddi},
      year={2023},
      eprint={2207.10062},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{grafberger2023towards,
  title={Towards Declarative Systems for Data-Centric Machine Learning},
  author={Grafberger, Stefan and Karla{\v{s}}, Bojan and Groth, Paul and Schelter, Sebastian},
  journal={DMLR workshop @ ICML},
  year={2023}
}

@article{stoyanovich2019nutritional,
  title={Nutritional labels for data and models},
  author={Stoyanovich, Julia and Howe, Bill},
  journal={A Quarterly bulletin of the Computer Society of the IEEE Technical Committee on Data Engineering},
  volume={42},
  number={3},
  year={2019}
}

@misc{airflow,
  title = {Apache Airflow},
  howpublished = {\url{https://airflow.apache.org/}}
}

@article{fang2020introducing,
  title={Introducing the model card toolkit for easier model transparency reporting},
  author={Fang, Huanming and Miao, Hui and Shukla, Karan and Nanas, Dan and Xu, Catherina and Greer, Christina and Polyzotis, Neoklis and Doshi, Tulsee and Deng, Tiffany and Mitchell, Margaret and others},
  journal={Google AI Blog},
  year={2020}
}

@article{tagliabue2021dag,
  title={DAG Card is the new Model Card}, 
  author={Jacopo Tagliabue and Ville Tuulos and Ciro Greco and Valay Dave},
  journal={DCAI workshop @ NeurIPS},
  year={2021}
}

@article{Katsiapis2020tfx,
  author       = {Konstantinos Katsiapis and
                  Abhijit Karmarkar and
                  Ahmet Altay and
                  Aleksandr Zaks and
                  Neoklis Polyzotis and
                  Anusha Ramesh and
                  Ben Mathes and
                  Gautam Vasudevan and
                  Irene Giannoumis and
                  Jarek Wilkiewicz and
                  Jiri Simsa and
                  Justin Hong and
                  Mitchell Trott and
                  No{\'{e}} Lutz and
                  Pavel A. Dournov and
                  Robert Crowe and
                  Sarah Sirajuddin and
                  Tris Brian Warkentin and
                  Zhitao Li},
  title        = {Towards {ML} Engineering: {A} Brief History Of TensorFlow Extended
                  {(TFX)}},
  journal      = {CoRR},
  volume       = {abs/2010.02013},
  year         = {2020},
  url          = {https://arxiv.org/abs/2010.02013},
  eprinttype    = {arXiv},
  eprint       = {2010.02013},
  timestamp    = {Mon, 12 Oct 2020 17:53:10 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2010-02013.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{rijn2013openml,
author="van Rijn, Jan N.
and Bischl, Bernd
and Torgo, Luis
and Gao, Bo
and Umaashankar, Venkatesh
and Fischer, Simon
and Winter, Patrick
and Wiswedel, Bernd
and Berthold, Michael R.
and Vanschoren, Joaquin",
editor="Blockeel, Hendrik
and Kersting, Kristian
and Nijssen, Siegfried
and {\v{Z}}elezn{\'y}, Filip",
title="OpenML: A Collaborative Science Platform",
booktitle="Machine Learning and Knowledge Discovery in Databases",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="645--649",
abstract="We present OpenML, a novel open science platform that provides easy access to machine learning data, software and results to encourage further study and application. It organizes all submitted results online so they can be easily found and reused, and features a web API which is being integrated in popular machine learning tools such as Weka, KNIME, RapidMiner and R packages, so that experiments can be shared easily.",
isbn="978-3-642-40994-3"
}

@misc{OpenMLDatasetUpload,
  title = {Dataset upload tutorial},
    author={OpenML},
  howpublished = {\url{https://openml.github.io/openml-python/develop/examples/30_extended/create_upload_tutorial.html}}
}

@misc{OpenMLDocs,
  title = {Documentation},
    author={OpenML},
  howpublished = {\url{https://docs.openml.org/}}
}

@misc{TFXMLMDDocs,
  title = {ML Metadata},
    author={Tensorflow Extended Guide},
  howpublished = {\url{https://www.tensorflow.org/tfx/guide/mlmd}}
}

@article{berg2019open,
  title={Open-Sourcing Metaflow, a Human-Centric Framework for Data Science},
  author={Berg, David and Chirravuri, Ravi Kiran and Cledat, Romain and Goyal, Savin and Hamad, Ferras and Tuulos, Ville},
  journal={Netflix Tech Blog},
  volume={201},
  year={2019}
}

@article{bleifuss2018change,
author = {Bleifu\ss{}, Tobias and Bornemann, Leon and Johnson, Theodore and Kalashnikov, Dmitri V. and Naumann, Felix and Srivastava, Divesh},
title = {Exploring change: a new dimension of data analytics},
year = {2018},
issue_date = {October 2018},
publisher = {VLDB Endowment},
volume = {12},
number = {2},
issn = {2150-8097},
url = {https://doi.org/10.14778/3282495.3282496},
doi = {10.14778/3282495.3282496},
abstract = {Data and metadata in datasets experience many different kinds of change. Values are inserted, deleted or updated; rows appear and disappear; columns are added or repurposed, etc. In such a dynamic situation, users might have many questions related to changes in the dataset, for instance which parts of the data are trustworthy and which are not? Users will wonder: How many changes have there been in the recent minutes, days or years? What kind of changes were made at which points of time? How dirty is the data? Is data cleansing required? The fact that data changed can hint at different hidden processes or agendas: a frequently crowd-updated city name may be controversial; a person whose name has been recently changed may be the target of vandalism; and so on. We show various use cases that benefit from recognizing and exploring such change.We envision a system and methods to interactively explore such change, addressing the variability dimension of big data challenges. To this end, we propose a model to capture change and the process of exploring dynamic data to identify salient changes. We provide exploration primitives along with motivational examples and measures for the volatility of data. We identify technical challenges that need to be addressed to make our vision a reality, and propose directions of future work for the data management community.},
journal = {Proc. VLDB Endow.},
month = {oct},
pages = {85–98},
numpages = {14}
}

@article{Ziawasch2016errors,
author = {Abedjan, Ziawasch and Chu, Xu and Deng, Dong and Fernandez, Raul Castro and Ilyas, Ihab F. and Ouzzani, Mourad and Papotti, Paolo and Stonebraker, Michael and Tang, Nan},
title = {Detecting data errors: where are we and what needs to be done?},
year = {2016},
issue_date = {August 2016},
publisher = {VLDB Endowment},
volume = {9},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/2994509.2994518},
doi = {10.14778/2994509.2994518},
abstract = {Data cleaning has played a critical role in ensuring data quality for enterprise applications. Naturally, there has been extensive research in this area, and many data cleaning algorithms have been translated into tools to detect and to possibly repair certain classes of errors such as outliers, duplicates, missing values, and violations of integrity constraints. Since different types of errors may coexist in the same data set, we often need to run more than one kind of tool. In this paper, we investigate two pragmatic questions: (1) are these tools robust enough to capture most errors in real-world data sets? and (2) what is the best strategy to holistically run multiple tools to optimize the detection effort? To answer these two questions, we obtained multiple data cleaning tools that utilize a variety of error detection techniques. We also collected five real-world data sets, for which we could obtain both the raw data and the ground truth on existing errors. In this paper, we report our experimental findings on the errors detected by the tools we tested. First, we show that the coverage of each tool is well below 100\%. Second, we show that the order in which multiple tools are run makes a big difference. Hence, we propose a holistic multi-tool strategy that orders the invocations of the available tools to maximize their benefit, while minimizing human effort in verifying results. Third, since this holistic approach still does not lead to acceptable error coverage, we discuss two simple strategies that have the potential to improve the situation, namely domain specific tools and data enrichment. We close this paper by reasoning about the errors that are not detectable by any of the tools we tested.},
journal = {Proc. VLDB Endow.},
month = {aug},
pages = {993–1004},
numpages = {12}
}

@inproceedings{mahdavi2019raha,
author = {Mahdavi, Mohammad and Abedjan, Ziawasch and Castro Fernandez, Raul and Madden, Samuel and Ouzzani, Mourad and Stonebraker, Michael and Tang, Nan},
title = {Raha: A Configuration-Free Error Detection System},
year = {2019},
isbn = {9781450356435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3299869.3324956},
doi = {10.1145/3299869.3324956},
abstract = {Detecting erroneous values is a key step in data cleaning. Error detection algorithms usually require a user to provide input configurations in the form of rules or statistical parameters. However, providing a complete, yet correct, set of configurations for each new dataset is not trivial, as the user has to know about both the dataset and the error detection algorithms upfront. In this paper, we present Raha, a new configuration-free error detection system. By generating a limited number of configurations for error detection algorithms that cover various types of data errors, we can generate an expressive feature vector for each tuple value. Leveraging these feature vectors, we propose a novel sampling and classification scheme that effectively chooses the most representative values for training. Furthermore, our system can exploit historical data to filter out irrelevant error detection algorithms and configurations. In our experiments, Raha outperforms the state-of-the-art error detection techniques with no more than 20 labeled tuples on each dataset.},
booktitle = {Proceedings of the 2019 International Conference on Management of Data},
pages = {865–882},
numpages = {18},
keywords = {semi-supervised learning, machine learning, label propagation, historical data, error detection, data cleaning, clustering, classification},
location = {Amsterdam, Netherlands},
series = {SIGMOD '19}
}

@article{narayan2022can,
  title={Can Foundation Models Wrangle Your Data?},
  author={Narayan, Avanika and Chami, Ines and Orr, Laurel and R{\'e}, Christopher},
  journal={Proceedings of the VLDB Endowment},
  volume={16},
  number={4},
  pages={738--746},
  year={2022},
  publisher={VLDB Endowment}
}

@article{jager2021benchmark,
  title={A Benchmark for Data Imputation Methods},
  author={J{\"a}ger, Sebastian and Allhorn, Arndt and Bie{\ss}mann, Felix},
  journal={Frontiers in Big Data},
  pages={48},
  year={2021},
  publisher={Frontiers}
}
