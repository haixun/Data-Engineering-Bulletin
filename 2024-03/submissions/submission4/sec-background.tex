\subsection{Foundation Models, \chat, and Existing Evaluation}

Foundation models have become a popular research and application paradigm for natural language process tasks.
Since foundation models are trained on large volumes of data, they show significant performance improvement on different downstream tasks such as sentiment analysis, question answering, automatic diagnosis, logical reasoning, and sequence tagging.
\chat is a generative foundation model that belongs to the GPT-3.5 series in OpenAI's GPT family, coming after GPT~\cite{radford2018improving}, GPT-2~\cite{radford2019language}, GPT-3~\cite{brown2020language}, and InstructGPT~\cite{ouyang2022training}.
In contrast to its predecessors, \chat makes it easy for every one to use just through a browser with enhanced multi-turn dialogue capabilities.
Although the technical details of \chat is still not released, it is known to be trained using reinforcement learning from human feedback (RLHF)~\cite{christiano2017deep} with instruction tuning.
Other than natural language processing, there are also emerging efforts in building foundation models for computer vision~\cite{dehghani2023scaling}, music generation~\cite{agostinelli2023musiclm}, biology~\cite{luo2022biogpt,lee2020biobert}, and speech recognition~\cite{radford2022robust}.

Previous efforts evaluate \chat in different aspects~\cite{van2023chatgpt}.
\cite{bang2023multitask} proposes a multi-task, multi-modal, and multilingual evaluation of \chat on different tasks.
They showed that \chat performs reasonably well on most tasks, while it does not bring great performance on low-resource tasks.
Similar empirical evaluations are also made by \cite{gozalo2023chatgpt,azaria2022chatgpt}.
Specifically, \cite{qin2023chatgpt} also did several evaluations and they found that \chat does not do well on fine-grained downstream tasks such as sequence tagging.
In addition to research from artificial intelligence, researchers from other areas also showed interest in \chat.
\cite{hacker2023regulating,shen2023chatgpt} expressed concerns that \chat and other large models should be regulated since they are double-edged swords.
The evaluations on ethics are done in \cite{zhuo2023exploring}.
There are reflections and discussions from law~\cite{choi2023chatgpt}, education~\cite{khalil2023will,m2022exploring,susnjak2022chatgpt,guo2023close}, human-computer interaction~\cite{tabone2023using}, medicine~\cite{jeblick2022chatgpt}, and writing~\cite{biswas2023chatgpt}.
To the best of our knowledge, a thorough robustness evaluation is currently under-explored.


\subsection{Robustness}
\label{sec-back-robust}


In the following, we present the formulation of robustness with the classification task (other tasks can be formulated similarly).
We are given a $K$-class classification dataset $\mathcal{D}=\{\mathbf{x}_i, y_i\}_{i=1}^n$, where $\mathbf{x} \in \mathbb{R}^d$ and $y \in [K]$ are its $d$-dimensional input and output, respectively.
We use $\ell[\cdot, \cdot]$ to denote the loss function.

\paragraph{Adversarial robustness}
An adversarial input~\cite{goodfellow2014explaining} $\mathbf{x}^\prime$ is generated by adding a $\epsilon$-bounded, imperceptible perturbation $\delta$ to the original input $\mathbf{x}$.
The optimal classifier can be learned by optimizing the following objective~\cite{madry2017towards}:
\begin{equation*}
    \min_{f \in \mathcal{H}} \mathbb{E}_{(\mathbf{x}, y) \in \mathcal{D}} \max_{|\delta| \le \epsilon} \ell [f(\mathbf{x} + \delta), y].
\end{equation*}

\paragraph{Out-of-distribution robustness}
On the other hand, OOD robustness (generalization)~\cite{wang2022generalizing,shen2021towards} aims to learn an optimal classifier on an unseen distribution by training on existing data.
One popular formulation for OOD robustness is to minimize the average risk on all distributions $e$, which is sampled over the set of all possible distributions (could be large than $\mathcal{D}$):
\begin{equation*}
    \min_{f \in \mathcal{H}} \mathbb{E}_{e \sim \mathcal{Q}} \mathbb{E}_{(\mathbf{x}, y) \in \mathcal{D}^e} \ell[f(\mathbf{x}), y].
\end{equation*}

\cite{yang2022glue} presented GLUE-X, a benchmark based on GLUE and then conducted a thorough evaluation of the OOD robustness of language models by training on in-distribution (ID) sets and then testing on OOD sets.
Ours, however, performs zero-shot evaluation.
The OOD robustness of \chat cannot be evaluated by GLUE and GLUE-X benchmarks since it may include the entire GLUE datasets in its training data.