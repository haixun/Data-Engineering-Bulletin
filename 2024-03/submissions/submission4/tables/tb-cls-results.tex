\begin{table}[t!]
\centering
\caption{Zero-shot classification results on adversarial (ASR$\downarrow$) and OOD (F1$\uparrow$) datasets. The best and second-best results are highlighted in \textbf{bold} and \underline{underline}.}
\label{tb-results}
\resizebox{.9\textwidth}{!}{
\begin{tabular}{l|cccccc|cc}
\toprule
\multirow{2}{*}{Model \& \#Param.} & \multicolumn{6}{c|}{Adversarial robustness (ASR$\downarrow$)} & \multicolumn{2}{c}{OOD robustness (F1$\uparrow$)} \\ 
 & \multicolumn{1}{c}{SST-2} & \multicolumn{1}{c}{QQP} & \multicolumn{1}{c}{MNLI} & \multicolumn{1}{c}{QNLI} & \multicolumn{1}{c}{RTE} & \multicolumn{1}{c|}{ANLI} & \multicolumn{1}{c}{Flipkart} & \multicolumn{1}{c}{\ddx}  \\ \midrule
Random & \multicolumn{1}{c}{50.0} & \multicolumn{1}{c}{50.0} & \multicolumn{1}{c}{66.7} & \multicolumn{1}{c}{50.0} & \multicolumn{1}{c}{50.0} & \multicolumn{1}{c}{66.7} & \multicolumn{1}{c}{20.0} & \multicolumn{1}{c}{4.0}  \\ \midrule
DeBERTa-L (435 M) & \multicolumn{1}{c}{66.9} & \multicolumn{1}{c}{39.7} & \multicolumn{1}{c}{64.5} & \multicolumn{1}{c}{46.6} & \multicolumn{1}{c}{60.5} & \multicolumn{1}{c|}{69.3} & \multicolumn{1}{c}{\textbf{60.6}} & \multicolumn{1}{c}{4.5} \\ 
% RoBERTa-L (560 M) & \multicolumn{1}{c}{46.6} & \multicolumn{1}{c}{60.3} & \multicolumn{1}{c}{60.3} & \multicolumn{1}{c}{\underline{49.3}} & \multicolumn{1}{c}{\textbf{43.2}} & \multicolumn{1}{c|}{63.0} & \multicolumn{1}{c}{55.6} & \multicolumn{1}{c}{0.0} \\ 
BART-L (407 M) & \multicolumn{1}{c}{56.1} & \multicolumn{1}{c}{62.8} & \multicolumn{1}{c}{58.7} & \multicolumn{1}{c}{52.0} & \multicolumn{1}{c}{56.8} & \multicolumn{1}{c|}{\underline{57.7}}  & \multicolumn{1}{c}{57.8} & \multicolumn{1}{c}{5.3}  \\ \midrule
GPT-J-6B (6 B) & \multicolumn{1}{c}{48.7} & \multicolumn{1}{c}{59.0} & \multicolumn{1}{c}{73.6} & \multicolumn{1}{c}{50.0} & \multicolumn{1}{c}{56.8} & \multicolumn{1}{c|}{66.5}  & \multicolumn{1}{c}{28.0} & \multicolumn{1}{c}{2.4}  \\ 
Flan-T5-L (11 B) & \multicolumn{1}{c}{\underline{40.5}} & \multicolumn{1}{c}{59.0} & \multicolumn{1}{c}{48.8} & \multicolumn{1}{c}{50.0} & \multicolumn{1}{c}{56.8} & \multicolumn{1}{c|}{68.6}  & \multicolumn{1}{c}{58.3} & \multicolumn{1}{c}{8.4}  \\ 
% T0 (11 B) & \multicolumn{1}{c}{\textbf{36.5}} & \multicolumn{1}{c}{60.3} & \multicolumn{1}{c}{72.7} & \multicolumn{1}{c}{50.0} & \multicolumn{1}{c}{56.8} & \multicolumn{1}{c|}{91.0}  & \multicolumn{1}{c}{\underline{58.8}} & \multicolumn{1}{c}{6.3}  \\ 
GPT-NEOX-20B (20 B) & \multicolumn{1}{c}{52.7} & \multicolumn{1}{c}{56.4} & \multicolumn{1}{c}{59.5} & \multicolumn{1}{c}{54.0} & \multicolumn{1}{c}{48.1} & \multicolumn{1}{c|}{70.0}  & \multicolumn{1}{c}{39.4} & \multicolumn{1}{c}{12.3}  \\ 
OPT-66B (66 B) & \multicolumn{1}{c}{47.6} & \multicolumn{1}{c}{53.9} & \multicolumn{1}{c}{60.3} & \multicolumn{1}{c}{52.7} & \multicolumn{1}{c}{58.0} & \multicolumn{1}{c|}{\underline{58.3}} & \multicolumn{1}{c}{44.5} & \multicolumn{1}{c}{0.3} \\ 
BLOOM (176 B) & \multicolumn{1}{c}{48.7} & \multicolumn{1}{c}{59.0} & \multicolumn{1}{c}{73.6} & \multicolumn{1}{c}{50.0} & \multicolumn{1}{c}{56.8} & \multicolumn{1}{c|}{66.5}  & \multicolumn{1}{c}{28.0} & \multicolumn{1}{c}{0.1} \\ 
text-davinci-002 (175 B) & \multicolumn{1}{c}{46.0} & \multicolumn{1}{c}{\underline{28.2}} & \multicolumn{1}{c}{54.6} & \multicolumn{1}{c}{45.3} & \multicolumn{1}{c}{35.8} & \multicolumn{1}{c|}{68.8}  & \multicolumn{1}{c}{57.5} & \multicolumn{1}{c}{18.9}  \\ 
text-davinci-003 (175 B) & \multicolumn{1}{c}{44.6} & \multicolumn{1}{c}{55.1} & \multicolumn{1}{c}{\underline{44.6}} & \multicolumn{1}{c}{\underline{38.5}} & \multicolumn{1}{c}{\underline{34.6}} & \multicolumn{1}{c|}{62.9}  & \multicolumn{1}{c}{57.3} & \multicolumn{1}{c}{\underline{19.6}}  \\ 
ChatGPT (175 B) & \multicolumn{1}{c}{\textbf{39.9}} & \multicolumn{1}{c}{\textbf{18.0}} & \multicolumn{1}{c}{\textbf{32.2}} & \multicolumn{1}{c}{\textbf{34.5}} & \multicolumn{1}{c}{\textbf{24.7}} & \multicolumn{1}{c|}{\textbf{55.3}}  & \multicolumn{1}{c}{\textbf{60.6}} & \multicolumn{1}{c}{\textbf{20.2}} \\ \bottomrule
\end{tabular}
}
\end{table}