\section{Discussion and Open Questions}
This section discusses the fine-grained provenance for DP systems related to traditional data provenance literature and the development of DP with their respective open questions.

\subsection{Relationship with Data Provenance}
The well-established field of data provenance offers valuable insights for the future development of DP provenance. In this work, we explored why, how, and where provenance for DP systems. To delve deeper, let's discuss two additional areas for consideration.

\stitle{Representations of Privacy Provenance.}
In traditional databases, provenance information can be represented using either an \emph{eager} or a \emph{lazy} approach. The eager approach~\cite{BunemanKT02annotations} attaches extra metadata (annotations) to queries and propagates it to the results, e.g., based on the provenance semirings~\cite{GreenT17provenance_semiring} or calculation of Shapley value~\cite{LuoPCX22,LuoPXZX24}. While this allows for direct retrieval of provenance information, it can incur performance overhead and require additional storage for the metadata. The lazy approach~\cite{cheney2009provenance} relies on properties of specific transformations to identify the source data behind the output without annotations. This method has lower overhead but limited applicability. In the context of DP provenance, we have primarily focused on leveraging and storing additional metadata, similar to the eager approach. It would be interesting to explore the feasibility of a lazy approach for DP provenance. This could involve developing mechanisms to answer why-, how-, and where-provenance queries without needing constant metadata storage and updates.


\stitle{Scalable Privacy Provenance Tracking.}
Research in database provenance has addressed the challenge of scalability in managing provenance information~\cite{geerts2006mondrian,srivastava2007intensional,chapman2008efficient,re2008approximate}. These methods aim to reduce the cost of tracking provenance by either minimizing the amount of extra metadata required or employing compression techniques to approximate provenance. For DP provenance, the level of granularity (detail) directly impacts the amount of data that needs to be tracked. Finer-grained provenance necessitates tracking more data. There are two key areas for further exploration. First, we would like to have a better understanding of the trade-off between privacy granularity and the associated storage and processing overhead. For instance, DProvDB can use a finer-grained caching mechanism like CacheDP~\cite{mazmudar2022cache} to further save privacy budget per query, but maintaining and updating such cache structures for all analysts can be very expensive.
This will guide future research efforts. Second, developing techniques to reduce the cost of privacy provenance tracking is a promising research direction. Existing systems, like DProvDB, which tracks analyst provenance at the view level for efficiency, offer valuable insights. Future work could explore compression and approximation techniques specifically tailored for efficient privacy provenance management.


\subsection{Relationship with the Development of DP}

Differential privacy has been around since 2006 and has evolved significantly. Today, we have a vast array of DP algorithms for various uses, different privacy definitions for various scenarios, and even prototype programming tools and systems. This article focuses on DP systems that leverage provenance techniques to improve usability or performance. The effectiveness of these provenance techniques is directly related to the development of DP algorithms and definitions. Let's explore some key areas for further exploration.

\stitle{Optimal Algorithm Design.}
Accuracy-first mechanisms are less understood compared to privacy-first mechanisms.  For accuracy-first mechanisms, how queries translate into privacy guarantees can vary depending on the specific queries, how accuracy is measured by the system, and even the data (e.g., joining tables or measuring relative error). Existing research for privacy-first mechanisms has produced optimal solutions for specific queries like joins~\cite{dong2022r2t,dong2021nearly,dong2021residual,XiaoBHG11relativeerror}. However, there is a gap in understanding how to achieve optimal results for accuracy-first mechanisms, particularly those that depend on the data.  Closing this gap is crucial for developing user-friendly DP systems that leverage why-DP-provenance. 

Recent advancements in DP mechanisms~\cite{mazmudar2022cache,ge2019apex,pioneer,WhitehouseRWR22brownian} involve using correlated noise drawn from different points over time. This approach can lead to tighter privacy analysis or improved utility for the results. However, effectively and securely maintaining these noise sequences is critical for successful deployment. This necessitates the development of systematic how-DP-provenance techniques in the future. 

Limited DP algorithms have been developed specifically for growing data models, and they often overlook how data evolves over time (e.g., their temporal properties). In machine learning, for instance, data patterns and learned models can change over time (i.e., the concept drift).  Factoring in concept drift will likely require even finer-grained how/where-DP-provenance tracking for effective solutions.

\stitle{Mixing DP Variants.}
DP provides some degree of freedom to allow system designers to ``composite'' privacy guarantees.
However, a key challenge arises if one part of the data is released with DP while others are queried and processed with other privacy notions, such as OSDP~\cite{kotsogiannis2020one}, attribute privacy~\cite{zhang2020attribute}, pufferfish privacy~\cite{kifer2014pufferfish}, etc., each with its own strengths and use cases. While combining these use cases into a unified system might be desirable, a significant question remains: how do we account for the total privacy loss when mixing different privacy-preserving techniques?
Recent research in encrypted databases~\cite{zhang2024SNF} explores similar challenges in reasoning about security when combining multiple encryption techniques.  This offers valuable insights for the DP domain. An interesting future direction would be to develop techniques specifically for mixing different privacy definitions and calculating the resulting privacy loss. One possibility is to leverage existing DP auditing techniques~\cite{PillutlaAKMOO23DP_audit,JagielskiUO20audit_DP,NasrH0BTJCT23DP_audit}. These techniques can help us establish a lower bound for the overall privacy guarantee, even when combining different privacy-preserving methods.


\stitle{Removing Trusted Curators in DP.}
Our discussion of privacy provenance has so far focused on centralized DP systems, which rely on a trusted curator to oversee the entire process. However, this centralized approach may not be practical in all real-world scenarios. Removing the need for a trusted party is an active area of research with several promising directions. First, local DP empowers data owners to add noise to their own data before it is used in queries. While this offers greater privacy control, it can lead to lower accuracy than centralized DP. Existing research has explored using anonymous shufflers~\cite{bittau2017prochlo,girgis2021renyi} to improve utility in local DP settings.  An interesting future direction would be to investigate how other privacy provenance information, besides shuffling, can be leveraged to enhance utility in local DP systems. Second, combining DP with cryptography~\cite{wagh2021dp,roy2020cryptœµ} offers another approach to reduce the noise needed for the local or federated settings~\cite{bonawitz2017practical,bao2022skellam}. Third,
enabling a DP system with trusted hardware, e.g., SGX~\cite{duetsgx}, can simulate the trusted curator in the untrusted settings. However, as shown in recent work~\cite{state_sgx}, the last two approaches have to maintain and track a significant amount of additional metadata about the state of the running environment. Without this metadata tracking, the system remains vulnerable.
Privacy provenance can be crucial in future work on these decentralized privacy-preserving techniques. Providing a systematic view of data usage and privacy guarantees can help address the challenges associated with removing the need for a trusted central authority in DP systems.

