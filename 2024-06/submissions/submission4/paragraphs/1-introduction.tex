\section{Introduction}
Time series are being generated on a large scale across a wide range of application domains, such as IoT, finance, healthcare monitoring, operational event logs, and smart home sensors. For example, smart home devices such as thermostats and humidity sensors generate continuous time series on environmental conditions, tracking temperature fluctuations and moisture levels to optimize home climate control based on user activities. Additionally, trajectories represent a unique type of time series that contain both spatial and temporal information, such as GPS data tracking the movement of vehicles or individuals. To facilitate the analysis of time series and support various downstream tasks,  numerous methods have been proposed, ranging from traditional statistical techniques, such as ARIMA~\cite{hyndman2018forecasting} and exponential smoothing~\cite{gardner2006exponential}, to advanced machine learning models, such as long short-term memory (LSTM) networks~\cite{shi2015convolutional}. However, a key issue in these time series applications is privacy. Since many data sources such as smart home sensors and location trajectories contain individuals' private information, the direct release or analysis of such time series can lead to significant privacy violations. Consequently, developing privacy-preserving mechanisms for time series analysis is essential.

Differential privacy (DP) ~\cite{Dwork2006} is a paradigm of privacy-preserving mechanisms that provides a theoretical privacy guarantee and has been further extended to the local setting to accommodate more general scenarios~\cite{ye2020local, Yang2023}. Numerous DP mechanisms have been developed to support various queries~\cite{wang2017locally, wang2018privacy, wang2019locallyhv}, including estimating statistics such as frequency~\cite{wang2017locally, fu2023collecting} and mean~\cite{li2020estimating}, ensuring that the privacy of individuals in the dataset is protected even when aggregate information is released. Recently, research has shifted towards more complex applications, such as graph data mining~\cite{ye2020towards} and machine learning problems~\cite{zhang2012functional}. Techniques such as differentially private stochastic gradient descent (DP-SGD)~\cite{abadi2016deep, fu2023dpsur} have been developed to train machine learning models with differential privacy guarantees, enabling the use of private datasets for tasks like classification and prediction without compromising individuals' privacy. It is worth noting that differential privacy is also being explored in the context of time series~\cite{dwork2010differential, chan2011private, Kellaris14}. This involves developing new mechanisms capable of handling the features of time series, ensuring that privacy is maintained.

Nevertheless, time series data present more challenges compared to other types of data due to their large volume, temporal correlation, and dynamic nature. The large volume, in particular, poses significant issues for privacy models, as protecting every element of a time series would degrade utility. To address this challenge, three privacy levels have been proposed~\cite{Kellaris14}: event-level privacy, which protects a single element in the time series; $w$-event level privacy, which provides a privacy guarantee for $w$ consecutive elements; and user-level privacy, which protects all elements associated with an individual. To enhance utility, sampling and filtering-based mechanisms~\cite{fan2013adaptive}, as well as privacy budget allocation strategies~\cite{Kellaris14}, have been suggested. Additionally, the correlations between elements can lead to privacy breaches~\cite{shao2020structured}, necessitating countermeasures to confine these correlations~\cite{cao2017quantifying, xiao2017loclok}. Given numerous research efforts in this field,  a taxonomy is necessary to summarize the existing works and identify areas for future research.

However, to the best of our knowledge, there is no up-to-date and comprehensive survey specifically for time series under differential privacy. Dwork and Roth~\cite{dwork2014algorithmic} coauthored a comprehensive survey on differential privacy, which seems outdated now in terms of state-of-the-art techniques. More recently, there are two surveys from Zhao et al.~\cite{zhao2022survey, zhao2024scenario} focusing on the concepts and applications of differential privacy, but they do not extensively cover time series.
Miranda-Pascual et al.~\cite{miranda2023sok} conducted a survey on trajectory data publication, which mainly talks about downstream tasks with little emphasis on privacy preservation. %In contrast, our literature review on trajectories is based on emergent privacy issues and the demand for trajectory release. 
The most relevant survey on time series under differential privacy is by Katsomallos et al.~\cite{katsomallos2019privacy}. However, since it was published in 2019, the paper does not reflect current technical trends, such as LDP, which now accounts for a crucial portion of privacy-preserving time series research. %Therefore, we present this survey to review time series under differential privacy and suggest future research directions.


%In this survey, we aim to provide a brief introduction to time series under differential privacy. Since the sequential nature of time series, it has three distinct privacy levels, each offering different degrees of privacy guarantees. Additionally, the complexity of basic queries in time series analysis necessitates a detailed introduction. We start by discussing the count query, which extends to more advanced estimations like frequency and histograms. Following this, we delve into sum and mean queries, including range queries of the sum. Furthermore, we examine various works focused on time series release. This part is categorized based on the type of content released: either through value perturbation or through the generation of synthetic data. We also emphasize a specific and popular application of time series: location-based services. In this context, we review papers according to their privacy models and the downstream applications they support. In our discussion of future directions, we highlight four key challenges according to privacy models, potential attacks, data types, and learning problems.

% describe the difficulty

In this survey, we aim to provide a comprehensive review of research works on time series under differential privacy. The main contents and paper organization are summarized as follows.
\begin{itemize}
	\item \textbf{Section~\ref{sec2}: Fundamental concepts of time series and differential privacy.} We first introduce the basic concepts of time series and differential privacy, including the definitions of differential privacy and the composition theorems. Additionally, we elucidate the three privacy levels specifically defined within the context of time series.
	\item \textbf{Section~\ref{sec3}: Count queries and corresponding advanced queries.} We begin with an introduction to count queries, and then present two core techniques for their realization: the binary tree-based mechanism~\cite{chan2011private} and the matrix mechanism~\cite{li2015matrix}. Following this, we discuss advanced queries, such as frequency and histogram estimations, which are based on count queries. Finally, we explore downstream applications derived from count queries.
	\item \textbf{Section~\ref{sec4}: Sum/mean queries and downstream applications.} We list sum and mean queries together  due to their inherent correlation. Following the introduction of sum and mean queries, we present the developed mechanisms for these queries. Subsequently, we review the literature on downstream applications.
	\item \textbf{Section~\ref{sec5}: Time series release.} We classify the literature into two categories: methods based on value perturbation and  methods based on synthesis. For value perturbation-based methods, we first review  privacy budget allocation strategies and then present the optimization strategies to improve utility. We then  introduce the synthesis-based methods, including those based on statistics and generative models. Additionally, we discuss the privacy models of the time series mechanisms and review a line of work that perturbs the temporal order rather than the values to accommodate value-critical scenarios.
	\item \textbf{Section~\ref{sec6}: Location based services and trajectory release.} Given that location based services are common applications under differential privacy, we dedicate a section to discussing the relevant literature.  To improve the utility, geo-indistinguishability~\cite{andres2013geo} was proposed to constrain the perturbation domain. Moreover, due to the apparent temporal correlation, the relationships between locations need to be considered. Finally, we present mechanisms designed for trajectory release based on perturbation and synthesis.
    \item \textbf{Section~\ref{sec7}: Open challenges.} We present a few future research directions for DP-based time series in terms of privacy model, potential correlation-based attacks, complex data type, and learning based problems.
\end{itemize}



%The remainder of this paper is organized as follows. Section~\ref{sec2} introduces the preliminaries on time series and differential privacy. Section~\ref{sec3} summarizes count queries under differential privacy, while Section~\ref{sec4} reviews sum and mean queries. Section~\ref{sec5} focuses on the time series release problem. Section~\ref{sec6} discusses mechanisms related to location based services. Finally, Section~\ref{sec7}  proposes some open challenges and Section 8 concludes the survey.

