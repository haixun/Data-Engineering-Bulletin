@article{peng2023check,
  title={Check your facts and try again: Improving large language models with external knowledge and automated feedback},
  author={Peng, Baolin and Galley, Michel and He, Pengcheng and Cheng, Hao and Xie, Yujia and Hu, Yu and Huang, Qiuyuan and Liden, Lars and Yu, Zhou and Chen, Weizhu and others},
  journal={arXiv preprint arXiv:2302.12813},
  year={2023}
}

@inproceedings{bengio2019system,
  title={From system 1 deep learning to system 2 deep learning},
  author={Bengio, Yoshua and others},
  booktitle={Posner lecture at NeurIPSâ€™2019, Neural Information Processing Systems, Vancouver, BC},
  year={2019}
}



@article{lazaridou2022internet,
  title={Internet-augmented language models through few-shot prompting for open-domain question answering},
  author={Lazaridou, Angeliki and Gribovskaya, Elena and Stokowiec, Wojciech and Grigorev, Nikolai},
  journal={arXiv preprint arXiv:2203.05115},
  year={2022}
}

@inproceedings{petroni-2020,
  author       = {Fabio Petroni and
                  Patrick S. H. Lewis and
                  Aleksandra Piktus and
                  Tim Rockt{\"{a}}schel and
                  Yuxiang Wu and
                  Alexander H. Miller and
                  Sebastian Riedel},
  title        = {How Context Affects Language Models' Factual Predictions},
  booktitle    = {Conference on Automated Knowledge Base Construction, (AKBC)},
  year         = {2020}
}



@inproceedings{li-etal-2023-large,
  title={Large Language Models with Controllable Working Memory},
  author={Li, Daliang and Rawat, Ankit Singh and Zaheer, Manzil and Wang, Xin and Lukasik, Michal and Veit, Andreas and Yu, Felix and Kumar, Sanjiv},
  booktitle={Findings of the Association for Computational Linguistics (ACL)},
  pages={1774--1793},
  year={2023}
}

@inproceedings{sun2023headtotail,
    title = "Head-to-Tail: How Knowledgeable are Large Language Models ({LLM}s)? {A}.{K}.{A}. Will {LLM}s Replace Knowledge Graphs?",
    author = "Sun, Kai  and
      Xu, Yifan  and
      Zha, Hanwen  and
      Liu, Yue  and
      Dong, Xin Luna",
    booktitle = "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL)",
    year = "2024",
}

@article{kandogan2024blueprint,
  title={A Blueprint Architecture of Compound AI Systems for Enterprise},
  author={Kandogan, Eser and Rahman, Sajjadur and Bhutani, Nikita and Zhang, Dan and Li Chen, Rafael and Mitra, Kushan and Gurajada, Sairam and Pezeshkpour, Pouya and Iso, Hayate and Feng, Yanlin and others},
  journal={arXiv e-prints},
  pages={arXiv--2406},
  year={2024}
}


@article{mishra2023characterizing,
  title={Characterizing Large Language Models as Rationalizers of Knowledge-intensive Tasks},
  author={Mishra, Aditi and Rahman, Sajjadur and Kim, Hannah and Mitra, Kushan and Hruschka, Estevam},
  journal={Findings of the Association for Computational Linguistics ACL 2024},
  year={2024}
}

@inproceedings{pezeshkpour2024large,
  title={Large Language Models Sensitivity to The Order of Options in Multiple-Choice Questions},
  author={Pezeshkpour, Pouya and Hruschka, Estevam},
  booktitle={Findings of the Association for Computational Linguistics: NAACL 2024},
  pages={2006--2017},
  year={2024}
}

@article{DBLP:journals/bdcc/NambiarM22,
  author       = {Athira M. Nambiar and
                  Divyansh Mundra},
  title        = {An Overview of Data Warehouse and Data Lake in Modern Enterprise Data
                  Management},
  journal      = {Big Data Cogn. Comput.},
  volume       = {6},
  number       = {4},
  pages        = {132},
  year         = {2022},
  url          = {https://doi.org/10.3390/bdcc6040132},
  doi          = {10.3390/BDCC6040132},
  timestamp    = {Sun, 15 Jan 2023 18:31:12 +0100},
  biburl       = {https://dblp.org/rec/journals/bdcc/NambiarM22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{armbrust2021lakehouse,
  title={Lakehouse: a new generation of open platforms that unify data warehousing and advanced analytics},
  author={Armbrust, Michael and Ghodsi, Ali and Xin, Reynold and Zaharia, Matei},
  booktitle={Proceedings of CIDR},
  volume={8},
  pages={28},
  year={2021}
}

@inproceedings{mallen-etal-2023-trust,
    title = "When Not to Trust Language Models: Investigating Effectiveness of Parametric and Non-Parametric Memories",
    author = "Mallen, Alex  and
      Asai, Akari  and
      Zhong, Victor  and
      Das, Rajarshi  and
      Khashabi, Daniel  and
      Hajishirzi, Hannaneh",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (ACL)",
    year = "2023"
}

@inproceedings{petroni-etal-2019-language,
    title = "Language Models as Knowledge Bases?",
    author = {Petroni, Fabio  and
      Rockt{\"a}schel, Tim  and
      Riedel, Sebastian  and
      Lewis, Patrick  and
      Bakhtin, Anton  and
      Wu, Yuxiang  and
      Miller, Alexander},
    editor = "Inui, Kentaro  and
      Jiang, Jing  and
      Ng, Vincent  and
      Wan, Xiaojun",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    year = "2019",
    pages = "2463--2473",
}

@inproceedings{wu2024less,
  title={Less is More for Long Document Summary Evaluation by LLMs},
  author={Wu, Yunshu and Iso, Hayate and Pezeshkpour, Pouya and Bhutani, Nikita and Hruschka, Estevam},
  booktitle={Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 2: Short Papers)},
  pages={330--343},
  year={2024}
}

@article{zhang2021survey,
  title={A survey on multi-task learning},
  author={Zhang, Yu and Yang, Qiang},
  journal={IEEE transactions on knowledge and data engineering},
  volume={34},
  number={12},
  pages={5586--5609},
  year={2021},
  publisher={IEEE}
}

@inproceedings{carlson2010toward,
  title={Toward an architecture for never-ending language learning},
  author={Carlson, Andrew and Betteridge, Justin and Kisiel, Bryan and Settles, Burr and Hruschka, Estevam and Mitchell, Tom},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={24},
  number={1},
  pages={1306--1313},
  year={2010}
}

@article{pezeshkpour2024multi,
  title={Multi-Conditional Ranking with Large Language Models},
  author={Pezeshkpour, Pouya and Hruschka, Estevam},
  journal={arXiv preprint arXiv:2404.00211},
  year={2024}
}

@inproceedings{sciavolino-etal-2021-simple,
    title = "Simple Entity-Centric Questions Challenge Dense Retrievers",
    author = "Sciavolino, Christopher  and
      Zhong, Zexuan  and
      Lee, Jinhyuk  and
      Chen, Danqi",
    editor = "Moens, Marie-Francine  and
      Huang, Xuanjing  and
      Specia, Lucia  and
      Yih, Scott Wen-tau",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    year = "2021",
    pages = "6138--6148"
}

@article{liu2023pre,
  title={Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing},
  author={Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
  journal={ACM Computing Surveys},
  volume={55},
  number={9},
  pages={1--35},
  year={2023},
  publisher={ACM New York, NY}
}

@article{ding2024retrieve,
  title={Retrieve only when it needs: Adaptive retrieval augmentation for hallucination mitigation in large language models},
  author={Ding, Hanxing and Pang, Liang and Wei, Zihao and Shen, Huawei and Cheng, Xueqi},
  journal={arXiv preprint arXiv:2402.10612},
  year={2024}
}


@inproceedings{feng2024cmdbench,
  title={CMDBench: A Benchmark for Coarse-to-fine Multimodal Data Discovery in Compound AI Systems},
  author={Feng, Yanlin and Rahman, Sajjadur and Feng, Aaron and Chen, Vincent and Kandogan, Eser},
  booktitle={Proceedings of the Conference on Governance, Understanding and Integration of Data for Effective and Responsible AI},
  pages={16--25},
  year={2024}
}

@article{maekawa2024holistic,
  title={Holistic Reasoning with Long-Context LMs: A Benchmark for Database Operations on Massive Textual Data},
  author={Maekawa, Seiji and Iso, Hayate and Bhutani, Nikita},
  journal={arXiv preprint arXiv:2410.11996},
  year={2024}
}

@inproceedings{maekawa-etal-2024-retrieval,
    title = "Retrieval Helps or Hurts? A Deeper Dive into the Efficacy of Retrieval Augmentation to Language Models",
    author = "Maekawa, Seiji  and
      Iso, Hayate  and
      Gurajada, Sairam  and
      Bhutani, Nikita",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL)",
    year = "2024",
    pages = "5506--5521"
}

@inproceedings{khattab2020colbert,
  title={Colbert: Efficient and effective passage search via contextualized late interaction over bert},
  author={Khattab, Omar and Zaharia, Matei},
  booktitle={Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval},
  pages={39--48},
  year={2020}
}

@inproceedings{krishna-etal-2023-longeval,
    title = "{L}ong{E}val: Guidelines for Human Evaluation of Faithfulness in Long-form Summarization",
    author = "Krishna, Kalpesh  and
      Bransom, Erin  and
      Kuehl, Bailey  and
      Iyyer, Mohit  and
      Dasigi, Pradeep  and
      Cohan, Arman  and
      Lo, Kyle",
    booktitle = "Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics",
    year = "2023",
    pages = "1650--1669"
}

@inproceedings{zhao2021calibrate,
  title={Calibrate before use: Improving few-shot performance of language models},
  author={Zhao, Zihao and Wallace, Eric and Feng, Shi and Klein, Dan and Singh, Sameer},
  booktitle={International Conference on Machine Learning},
  pages={12697--12706},
  year={2021},
  organization={PMLR}
}

@article{qin2023large,
  title={Large language models are effective text rankers with pairwise ranking prompting},
  author={Qin, Zhen and Jagerman, Rolf and Hui, Kai and Zhuang, Honglei and Wu, Junru and Shen, Jiaming and Liu, Tianqi and Liu, Jialu and Metzler, Donald and Wang, Xuanhui and others},
  journal={arXiv preprint arXiv:2306.17563},
  year={2023}
}

@article{fabbri2021summeval,
    title = "{S}umm{E}val: Re-evaluating Summarization Evaluation",
    author = "Fabbri, Alexander R.  and
      Kry{\'s}ci{\'n}ski, Wojciech  and
      McCann, Bryan  and
      Xiong, Caiming  and
      Socher, Richard  and
      Radev, Dragomir",
    journal = "Transactions of the Association for Computational Linguistics (TACL)",
    volume = "9",
    year = "2021",
    pages = "391--409"
}

@inproceedings{bhandari-etal-2020-evaluating,
    title = "Re-evaluating Evaluation in Text Summarization",
    author = "Bhandari, Manik  and
      Gour, Pranav Narayan  and
      Ashfaq, Atabak  and
      Liu, Pengfei  and
      Neubig, Graham",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    publisher = "Association for Computational Linguistics",
    pages = "9347--9359",
}

@article{liu2023lost,
  title={Lost in the middle: How language models use long contexts},
  author={Liu, Nelson F and Lin, Kevin and Hewitt, John and Paranjape, Ashwin and Bevilacqua, Michele and Petroni, Fabio and Liang, Percy},
  journal={arXiv preprint arXiv:2307.03172},
  year={2023},
  url={https://arxiv.org/abs/2307.03172}
}

@electronic{indeed-ai-blog,
 author   = "Indeed",
 title     = "Indeed uses OpenAI to deliver contextual job matching to millions of job seekers",
 url       = "https://openai.com/index/indeed/"
}

@electronic{linkedin-ai-blog,
 author   = "LinkedIn",
 title     = "Musings on building a Generative AI product",
 url       = "https://www.linkedin.com/blog/engineering/generative-ai/musings-on-building-a-generative-ai-product"
}

@electronic{microsoft-magentic,
 author   = "Microsoft",
 title     = "Magentic-One: A Generalist Multi-Agent System for Solving Complex Tasks",
 url       = "https://www.microsoft.com/en-us/research/articles/magentic-one-a-generalist-multi-agent-system-for-solving-complex-tasks/"
}


@electronic{databricks-aibi,
 author   = "Databricks",
 title     = "Musings on building a Generative AI product",
 url       = "https://www.microsoft.com/en-us/research/articles/magentic-one-a-generalist-multi-agent-system-for-solving-complex-tasks/"
}

@inproceedings{stites2021sage,
  title={Sage advice? The impacts of explanations for machine learning models on human decision-making in spam detection},
  author={Stites, Mallory C and Nyre-Yu, Megan and Moss, Blake and Smutz, Charles and Smith, Michael R},
  booktitle={International Conference on Human-Computer Interaction},
  pages={269--284},
  year={2021},
  organization={Springer}
}

@inproceedings{wang2022self,
  title={Self-Consistency Improves Chain of Thought Reasoning in Language Models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc V and Chi, Ed H and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  booktitle={The Eleventh International Conference on Learning Representations}
}

@electronic{salesforce-agentforce,
 author   = "Salesforce",
 title     = "Agentforce: Build the Future with AI Agents",
 url       = "https://www.salesforce.com/agentforce/"
}

@electronic{linkedin-assistant,
 author   = "LinkedIn",
 title     = "Introducing Hiring Assistant for Recruiter \& Jobs",
 url       = "https://business.linkedin.com/talent-solutions/hiring-assistant"
}


@inproceedings{koh-etal-2022-far,
    title = "How Far are We from Robust Long Abstractive Summarization?",
    author = "Koh, Huan Yee  and
      Ju, Jiaxin  and
      Zhang, He  and
      Liu, Ming  and
      Pan, Shirui",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    year = "2022",
    pages = "2682--2698",
}

@article{zhuang2023setwise,
  title={A setwise approach for effective and highly efficient zero-shot ranking with large language models},
  author={Zhuang, Shengyao and Zhuang, Honglei and Koopman, Bevan and Zuccon, Guido},
  journal={arXiv preprint arXiv:2310.09497},
  year={2023}
}

@article{hoffman2018metrics,
  title={Metrics for explainable AI: Challenges and prospects},
  author={Hoffman, Robert R and Mueller, Shane T and Klein, Gary and Litman, Jordan},
  journal={arXiv preprint arXiv:1812.04608},
  year={2018}
}

@article{hoff2015trust,
  title={Trust in automation: Integrating empirical evidence on factors that influence trust},
  author={Hoff, Kevin Anthony and Bashir, Masooda},
  journal={Human factors},
  volume={57},
  number={3},
  pages={407--434},
  year={2015},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}



