\begin{thebibliography}{10}
\itemsep=1pt
\begin{small}

\bibitem{sun2023head} Sun, K. et al.. 
\newblock Head-to-tail: How knowledgeable are large language models (llm)? AKA will llms replace knowledge graphs?. 
\newblock \emph{arXiv preprint arXiv:2308.10168}, , 2023.
\bibitem{liang2023holistic} Liang, P. et al.. 
\newblock Holistic evaluation of language models. 
\newblock \emph{arXiv preprint arXiv:2211.09110}, , 2022.
\bibitem{ScienceQA} Lu, P. et al.. 
\newblock Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering. 
, 2022.
\bibitem{yao2023editing} Yao, Y. et al.. 
\newblock Editing large language models: Problems, methods, and opportunities. 
\newblock \emph{arXiv preprint arXiv:2305.13172}, , 2023.
\bibitem{TruthfulQA} Lin, S. et al.. 
\newblock TruthfulQA: Measuring How Models Mimic Human Falsehoods. 
:3214--3252, 2022.
\bibitem{weller2023according} Weller, O. et al.. 
\newblock " According to..." Prompting Language Models Improves Quoting from Pre-Training Data. 
\newblock \emph{arXiv preprint arXiv:2305.13252}, , 2023.
\bibitem{bolton2024biomedlm} Elliot Bolton,  et al.. 
\newblock BioMedLM: A 2.7B Parameter Language Model Trained On Biomedical Text. 
, 2024.
\bibitem{yasunaga2022deep} Yasunaga, M. et al.. 
\newblock Deep bidirectional language-knowledge graph pretraining. 
\newblock \emph{Advances in Neural Information Processing Systems}, 35:37309--37323, 2022.
\bibitem{TempQuestions} Jia, Z. et al.. 
\newblock Tempquestions: A benchmark for temporal question answering. 
:1057--1062, 2018.
\bibitem{dao2023flashattention2} Dao, T.. 
\newblock Flashattention-2: Faster attention with better parallelism and work partitioning. 
\newblock \emph{arXiv preprint arXiv:2307.08691}, , 2023.
\bibitem{auer2007dbpedia} Auer, S. et al.. 
\newblock Dbpedia: A nucleus for a web of open data. 
:722--735, 2007.
\bibitem{wang2024blendfilter} Haoyu Wang,  et al.. 
\newblock BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering. 
, 2024.
\bibitem{diao2023mixtureofdomainadapters} Shizhe Diao,  et al.. 
\newblock Mixture-of-Domain-Adapters: Decoupling and Injecting Domain Knowledge to Pre-trained Language Models Memories. 
, 2023.
\bibitem{lewis2020retrieval} Lewis, P. et al.. 
\newblock Retrieval-augmented generation for knowledge-intensive nlp tasks. 
\newblock \emph{Advances in Neural Information Processing Systems}, 33:9459--9474, 2020.
\bibitem{azaria-mitchell-2023-internal} Azaria, A., Mitchell, T.. 
\newblock The Internal State of an LLM Knows When Itâ€™s Lying. 
:967--976, 2023.
\bibitem{gallegos2023bias} Gallegos, I.O. et al.. 
\newblock Bias and Fairness in Large Language Models: A Survey. 
\newblock \emph{arXiv preprint arXiv:2309.00770}, , 2023.
\bibitem{kotha2023understanding} Kotha, S. et al.. 
\newblock Understanding catastrophic forgetting in language models via implicit inference. 
\newblock \emph{arXiv preprint arXiv:2309.10105}, , 2023.
\bibitem{liu2021p} Liu, X. et al.. 
\newblock P-tuning v2: Prompt tuning can be comparable to fine-tuning universally across scales and tasks. 
\newblock \emph{arXiv preprint arXiv:2110.07602}, , 2021.
\bibitem{wang2023survey} Wang, C. et al.. 
\newblock Survey on factuality in large language models: Knowledge, retrieval and domain-specificity. 
\newblock \emph{arXiv preprint arXiv:2310.07521}, , 2023.
\bibitem{carlson2010toward} Carlson, A. et al.. 
\newblock Toward an architecture for never-ending language learning. 
24:1306--1313, 2010.
\bibitem{NaturalQuestions} Kwiatkowski, T. et al.. 
\newblock Natural Questions: A Benchmark for Question Answering Research. 
\newblock \emph{Transactions of the Association for Computational Linguistics}, 7:453--466, 2019. MIT Press-Journals.
\bibitem{feng-etal-2023-factkb} Feng, S. et al.. 
\newblock FactKB: Generalizable Factuality Evaluation using Language Models Enhanced with Factual Knowledge. 
:933--952, 2023.
\bibitem{kim2023kggpt} Kim, J. et al.. 
\newblock KG-GPT: A general framework for reasoning on knowledge graphs using large language models. 
\newblock \emph{arXiv preprint arXiv:2310.11220}, , 2023.
\bibitem{tian2023finetuning} Tian, K. et al.. 
\newblock Fine-tuning language models for factuality. 
\newblock \emph{arXiv preprint arXiv:2311.08401}, , 2023.
\bibitem{luo2023reasoning} Luo, L. et al.. 
\newblock Reasoning on graphs: Faithful and interpretable large language model reasoning. 
\newblock \emph{arXiv preprint arXiv:2310.01061}, , 2023.
\bibitem{chen2023felm} Shiqi Chen,  et al.. 
\newblock {FELM}: Benchmarking Factuality Evaluation of Large Language Models. 
, 2023.
\bibitem{berglund2023reversal} Berglund, L. et al.. 
\newblock The Reversal Curse: LLMs trained on" A is B" fail to learn" B is A". 
\newblock \emph{arXiv preprint arXiv:2309.12288}, , 2023.
\bibitem{bollacker2008freebase} Bollacker, K. et al.. 
\newblock Freebase: a collaboratively created graph database for structuring human knowledge. 
:1247--1250, 2008.
\bibitem{wang2024myanswer} Wang, X. et al.. 
\newblock " My Answer is C": First-Token Probabilities Do Not Match Text Answers in Instruction-Tuned Language Models. 
\newblock \emph{arXiv preprint arXiv:2402.14499}, , 2024.
\bibitem{ben2010theory} Ben-David, S. et al.. 
\newblock A theory of learning from different domains. 
\newblock \emph{Machine learning}, 79:151--175, 2010. Springer.
\bibitem{wang2022preserving} Wang, Y. et al.. 
\newblock Preserving In-Context Learning ability in Large Language Model Fine-tuning. 
\newblock \emph{arXiv preprint arXiv:2211.00635}, , 2022.
\bibitem{liu-etal-2022-p} Liu, X. et al.. 
\newblock P-Tuning: Prompt Tuning Can Be Comparable to Fine-tuning Across Scales and Tasks. 
:61--68, 2022.
\bibitem{jiang-etal-2023-reasoninglm} Jiang, J. et al.. 
\newblock ReasoningLM: Enabling Structural Subgraph Reasoning in Pre-trained Language Models for Question Answering over Knowledge Graph. 
:3721--3735, 2023.
\bibitem{EvaluationSurvey} Chang, Y. et al.. 
\newblock A survey on evaluation of large language models. 
\newblock \emph{ACM Transactions on Intelligent Systems and Technology}, , 2023. ACM New York, NY.
\bibitem{wang2023evaluating} Cunxiang Wang,  et al.. 
\newblock Evaluating Open-{QA} Evaluation. 
, 2023.
\bibitem{goodfellow2015empirical} Goodfellow, I.J. et al.. 
\newblock An empirical investigation of catastrophic forgetting in gradient-based neural networks. 
\newblock \emph{arXiv preprint arXiv:1312.6211}, , 2013.
\bibitem{zhai2023investigating} Zhai, Y. et al.. 
\newblock Investigating the Catastrophic Forgetting in Multimodal Large Language Models. 
\newblock \emph{arXiv preprint arXiv:2309.10313}, , 2023.
\bibitem{zhou2023dont} Zhou, K. et al.. 
\newblock Don't Make Your LLM an Evaluation Benchmark Cheater. 
\newblock \emph{arXiv preprint arXiv:2311.01964}, , 2023.
\bibitem{zhang2023siren} Zhang, Y. et al.. 
\newblock Siren's song in the AI ocean: a survey on hallucination in large language models. 
\newblock \emph{arXiv preprint arXiv:2309.01219}, , 2023.
\bibitem{TQ} Joshi, M. et al.. 
\newblock TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension. 
:1601--1611, 2017.
\bibitem{suchanek2007yago} Suchanek, F.M. et al.. 
\newblock Yago: a core of semantic knowledge. 
:697--706, 2007.
\bibitem{MMLU} Dan Hendrycks,  et al.. 
\newblock Measuring Massive Multitask Language Understanding. 
\newblock \emph{Proceedings of the International Conference on Learning Representations (ICLR)}, , 2021.
\bibitem{bordes2013translating} Bordes, A. et al.. 
\newblock Translating embeddings for modeling multi-relational data. 
\newblock \emph{Advances in neural information processing systems}, 26, 2013.
\bibitem{gemmateam2024gemma} Team, G. et al.. 
\newblock Gemma: Open models based on gemini research and technology. 
\newblock \emph{arXiv preprint arXiv:2403.08295}, , 2024.
\bibitem{zhang2024knowledge} Zhang, M. et al.. 
\newblock Knowledge Graph Enhanced Large Language Model Editing. 
\newblock \emph{arXiv preprint arXiv:2402.13593}, , 2024.
\bibitem{C-Eval} Huang, Y. et al.. 
\newblock C-eval: A multi-level multi-discipline chinese evaluation suite for foundation models. 
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.
\bibitem{liu2023we} Liu, A. et al.. 
\newblock We're Afraid Language Models Aren't Modeling Ambiguity. 
\newblock \emph{arXiv preprint arXiv:2304.14399}, , 2023.
\bibitem{ren2023investigating} Ren, R. et al.. 
\newblock Investigating the factual knowledge boundary of large language models with retrieval augmentation. 
\newblock \emph{arXiv preprint arXiv:2307.11019}, , 2023.
\bibitem{touvron2023llama} Touvron, H. et al.. 
\newblock Llama 2: Open foundation and fine-tuned chat models. 
\newblock \emph{arXiv preprint arXiv:2307.09288}, , 2023.
\bibitem{chen2020recall} Chen, S. et al.. 
\newblock Recall and Learn: Fine-tuning Deep Pretrained Language Models with Less Forgetting. 
:7870--7881, 2020.
\bibitem{tan2023chatgpt} Tan, Y. et al.. 
\newblock Can ChatGPT replace traditional KBQA models? An in-depth analysis of the question answering performance of the GPT LLM family. 
:348--367, 2023.
\bibitem{CommonsenseQA} Talmor, A., Herzig, J., Lourie, N., and Berant, J.
\newblock CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge.
\newblock \emph{arXiv preprint arXiv:1811.00937}, 2019.
\newblock \url{https://arxiv.org/abs/1811.00937}.
\end{small}
\end{thebibliography}
