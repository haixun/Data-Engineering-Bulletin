%!TEX root = ../main.tex
\begin{abstract}
Large Language Models (LLMs) have revolutionized access to multimodal data lakes, enabling users to query and analyze complex information across diverse data modalities using natural language. However, their generative nature unavoidably leads to hallucinations, resulting in inaccuracies and misinformation in models like GPT, Llama, and Gemini. To address this, we introduce \sys, a system designed for trustworthy question answering and verification using multimodal data lakes.
%
\sys supports two core functions: reasoning and verification. In reasoning, \sys retrieves relevant information from multimodal data sources, breaks down complex queries into manageable sub-questions, and uses specialized tools (\eg LLMs or DBMS) to generate grounded answers. For verification, it cross-checks (LLM) generated answers against trusted sources, such as private or enterprise data lakes, to enhance accuracy and reliability. By integrating these processes, \sys mitigates factual inaccuracies, aligns outputs with trusted data, and adapts to a wide range of applications.
\end{abstract}