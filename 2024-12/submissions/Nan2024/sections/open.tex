%!TEX root = ../main.tex
\section{Open Problems}
\label{sec:open}

\stitle{Cross-Modal Data Discovery.}
Data discovery presents a significant challenge within data preparation, especially when dealing with data lakes that store diverse types of data across various formats, including structured data (\eg tables), semi-structured data (\eg graphs), and unstructured data (\eg images and videos).
%
Unlike data lakes containing only relational tables, discovering relevant data across multiple modalities requires addressing the inherent heterogeneity of these data types.
%
One promising direction for tackling this challenge is to explore cross-modal representation learning, which encodes data from different modalities into a unified vector space. This approach can enable a streamlined data discovery process by supporting embedding-based similarity search.
%
While we have made initial strides in cross-modal representation, our current work has not touched the surface of modeling relationships across different data modalities. Further research is needed to deepen our understanding and improve cross-modal data discovery methods.

\stitle{Cross-Modal Data Reasoning and Verification.}
One of the complexity of cross-modal reasoning and verification stems from the intricate relationships between different data modalities, such as text, images, and structured data (\eg tables and knowledge graphs). Each modality often possesses unique characteristics and contextual information that can complicate the verification process. For instance, verifying a claim made in textual data may require correlating it with relevant knowledge graph entities or structured data, where mismatches in representation and interpretation can lead to inaccuracies.
Current large language models, such as GPT, demonstrate reasonable performance in reasoning across diverse data types; however, there remains significant room for improvement, particularly regarding privacy and accuracy. To address these challenges, promising directions include the development of domain-specific models that focus on the interactions between specific modalities, improved representation learning techniques for better alignment of data types, and hybrid approaches that combine local and large language models. Additionally, privacy-preserving techniques, such as federated learning and iterative feedback mechanisms, could enhance the robustness and reliability of cross-modal reasoning and verification. These strategies aim to create a more effective framework for ensuring the accuracy and trustworthiness of generative AI outputs across different modalities.

\stitle{Trustworthiness of Data Sources.}
The accuracy of discovering and verifying data across different modalities in a data lake can be influenced by the quality and reliability of the underlying data sources. 
Therefore, it is crucial to assess the trustworthiness of different sources accurately to enhance the overall accuracy and reliability of the entire verification process.