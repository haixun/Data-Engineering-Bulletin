\documentclass[11pt]{article} % DO NOT CHANGE THIS
\usepackage{deauthor}
\usepackage{natbib}
\usepackage{hyperref}  
\usepackage{graphicx}  % hyperlinks
\usepackage{url} 
\usepackage{xcolor}
\usepackage{wrapfig}% simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

\usepackage{microtype}
\usepackage{amsmath}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{multirow}
\usepackage{subcaption}
\usepackage{bm}
\usepackage{stfloats}
\usepackage{arydshln}
%\usepackage{inconsolata}
\usepackage{graphicx}  
\usepackage{comment}
\usepackage{enumitem}

\newcommand{\ie}{\textit{i.e.}}
\newcommand{\eg}{\textit{e.g.}}
\setcounter{secnumdepth}{2} %May be changed to 1 or 2 if section numbers are desired.

\begin{document}

\title{\textsc{ReFIT}: Reranker Relevance Feedback during Inference}
\pagestyle{plain}
\author{\textbf{Revanth Gangi Reddy}$^1$ \hspace{0.2em} \textbf{Pradeep Dasigi}$^2$ \hspace{0.2em} \textbf{Md Arafat Sultan}$^3$ \hspace{0.2em} \textbf{Arman Cohan}$^{2,4}$ \\ \textbf{Avirup Sil}$^3$ \hspace{0.2em} \textbf{Heng Ji}$^1$ \hspace{0.2em} \textbf{Hannaneh Hajishirzi}$^{2,5}$ \\
$^1$University of Illinois at Urbana-Champaign \hspace{0.5em}  $^2$Allen Institute for AI \\ $^3$IBM Research AI \hspace{0.5em} $^4$Yale University \hspace{0.2em} $^5$University of Washington\\
  \texttt{\{revanth3,hengji\}@illinois.edu} \hspace{0.4em} \texttt{\{pradeepd,armanc,hannah\}@allenai.org} \\
  \texttt{arafat.sultan@ibm.com}\hspace{0.4em} \texttt{avi@us.ibm.com}
  }
\maketitle

\begin{abstract}

Retrieve-and-rerank is a prevalent framework in neural information retrieval, wherein a bi-encoder network initially retrieves a pre-defined number of candidates (\eg{}, $K$=100), which are then reranked by a more powerful cross-encoder model. While the reranker often yields improved candidate scores compared to the retriever, its scope is confined to only the top $K$ retrieved candidates. As a result, the reranker cannot improve retrieval performance in terms of Recall@K. In this work, we propose to leverage the reranker to improve recall by making it provide relevance feedback to the retriever at \textit{inference-time}. Specifically, given a test instance during inference, we distill the reranker's predictions for that instance into the retriever's query representation using a lightweight update mechanism. The aim of the distillation loss is to align the retriever's candidate scores more closely with those produced by the reranker. The algorithm then proceeds by executing a second retrieval step using the updated query vector. We empirically demonstrate that this method, applicable to various retrieve-and-rerank frameworks, substantially enhances the retrieval recall across multiple domains, languages, and modalities.

\end{abstract}

\input{submissions/Revanth2024/sections/introduction}

\input{submissions/Revanth2024/sections/related}

\input{submissions/Revanth2024/sections/method}

\input{submissions/Revanth2024/sections/experiments}

\section{Conclusion and Future Work}
We demonstrate that query representations can be improved using feedback from a cross-encoder reranker \textit{at inference time} for better performance of dual-encoder retrieval. This work proposes for distillation using relevance feedback from the reranker as a better and faster alternative to the traditional strategy of reranking a larger pool of candidates for improving recall.
\textsc{ReFIT} is lightweight and improves retrieval accuracy across different domains, languages and modalities over a state-of-the-art retrieve-and-rerank pipeline with comparable latency. Future work will focus on the potential integration of textual relevance feedback from large language models (LLMs). Additionally, a promising area of exploration lies in enhancing the interpretability by examining how relevance feedback influences the significance of individual query terms within the query representation.


\section{Limitations}

\textsc{ReFIT} introduces an additional latency into a traditional retrieve-and-rerank framework.
The distillation time is only dependent on the number of updates, and is unaffected by the model architecture  and number of retrieved passages; the overall additional latency (as per Table \ref{tab:inf_times}) amounts to an extra 17.5\% on GPU (or 4.4\% on CPU) when the number of retrieved passages $K$=100. However, it is noteworthy that \textsc{ReFIT} remains faster and exhibits superior performance compared to the standard approach of reranking a larger pool of candidates for improving recall.
Moreover, the efficacy of our approach is contingent upon the reranker providing a better ranking than the retriever. We anticipate that our method might provide minimal gains in situations where the retriever performs similar to the reranker.

\bibliographystyle{ieeetr}

\bibliography{submissions/Revanth2024/sample-base}

\end{document}
